{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb13ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Beta version: Let's listen to only the most accurate forecasters\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# Top-N forecaster ensemble • mean vs inverse-MSE weighting\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import norm, binomtest\n",
    "\n",
    "# 🔇 suppress every warning category\n",
    "warnings.filterwarnings(\"ignore\")          # ← one line does it all\n",
    "np.seterr(all=\"ignore\")                    # silence NumPy runtime warnings\n",
    "\n",
    "WINDOWS = [3, 6, 12]\n",
    "TOP_NS  = [5, 10, 15, 20, 25]\n",
    "RIDGE   = 1e-6\n",
    "\n",
    "PANELS = {\"Full panel\": df_full, \"COVID-filtered panel\": df}\n",
    "\n",
    "def evaluate_panel(panel: pd.DataFrame, label: str) -> pd.DataFrame:\n",
    "    dates = np.sort(panel[\"release_date\"].unique())\n",
    "    metrics = []\n",
    "\n",
    "    for W in tqdm(WINDOWS, desc=f\"{label}: windows\"):\n",
    "        for N in TOP_NS:\n",
    "            rows = []\n",
    "\n",
    "            for idx in range(W, len(dates)):\n",
    "                t = dates[idx]\n",
    "                hist = panel[panel[\"release_date\"]\n",
    "                             .between(dates[idx - W], dates[idx - 1])]\n",
    "\n",
    "                elig = hist.groupby(\"economist\")[\"forecast\"].apply(lambda s: s.notna().all())\n",
    "                econs = elig[elig].index\n",
    "                if econs.empty:\n",
    "                    continue\n",
    "\n",
    "                mse = (hist[hist[\"economist\"].isin(econs)]\n",
    "                       .groupby(\"economist\")[\"error\"]\n",
    "                       .apply(lambda s: np.mean(s**2)))\n",
    "                top = mse.nsmallest(N).index          # up to N forecasters\n",
    "\n",
    "                cur = panel[(panel[\"release_date\"] == t) &\n",
    "                            (panel[\"economist\"].isin(top))]\n",
    "                f_t = cur.set_index(\"economist\")[\"forecast\"].dropna()\n",
    "                if f_t.empty:\n",
    "                    continue\n",
    "\n",
    "                weights = {\n",
    "                    \"mean\": pd.Series(1 / len(f_t), index=f_t.index),\n",
    "                    \"inv_mse\": 1 / (mse.loc[f_t.index] + RIDGE)\n",
    "                }\n",
    "                weights[\"inv_mse\"] /= weights[\"inv_mse\"].sum()\n",
    "\n",
    "                median_all = panel.loc[panel[\"release_date\"] == t,\n",
    "                                       \"forecast\"].dropna().median()\n",
    "                actual = panel.loc[panel[\"release_date\"] == t,\n",
    "                                   \"actual\"].iloc[0]\n",
    "\n",
    "                for method, w in weights.items():\n",
    "                    smart = np.dot(w, f_t)\n",
    "                    pred_dir = int(smart > median_all)\n",
    "                    actual_dir = int(actual > median_all) if pd.notna(actual) else np.nan\n",
    "                    rows.append((W, len(f_t), method, t,\n",
    "                                 smart, median_all, actual,\n",
    "                                 pred_dir, actual_dir))\n",
    "\n",
    "            if not rows:\n",
    "                continue\n",
    "\n",
    "            df_all = pd.DataFrame(rows, columns=[\n",
    "                \"window\", \"top_N\", \"method\", \"date\",\n",
    "                \"smart\", \"median\", \"actual\", \"pred_dir\", \"actual_dir\"\n",
    "            ])\n",
    "            eval_df = df_all.dropna(subset=[\"actual\"])\n",
    "            if eval_df.empty:\n",
    "                continue\n",
    "\n",
    "            eval_df[\"smart_err\"]  = eval_df[\"smart\"]  - eval_df[\"actual\"]\n",
    "            eval_df[\"median_err\"] = eval_df[\"median\"] - eval_df[\"actual\"]\n",
    "\n",
    "            obs     = len(eval_df)\n",
    "            rmse_s  = np.sqrt((eval_df[\"smart_err\"]**2).mean())\n",
    "            rmse_m  = np.sqrt((eval_df[\"median_err\"]**2).mean())\n",
    "\n",
    "            diff = eval_df[\"smart_err\"]**2 - eval_df[\"median_err\"]**2\n",
    "            dm_p = 2 * (1 - norm.cdf(abs(diff.mean() / diff.std(ddof=1) *\n",
    "                                         np.sqrt(obs))))\n",
    "\n",
    "            # directional metrics\n",
    "            hits     = (eval_df[\"pred_dir\"] == eval_df[\"actual_dir\"]).sum()\n",
    "            hit_rate = hits / obs\n",
    "            binom_p  = binomtest(hits, obs, 0.5).pvalue\n",
    "\n",
    "            p1, p2 = eval_df[\"pred_dir\"].mean(), eval_df[\"actual_dir\"].mean()\n",
    "            joint  = ((eval_df[\"pred_dir\"].astype(int) &\n",
    "                       eval_df[\"actual_dir\"].astype(int))).mean()\n",
    "            pt_stat = (joint - p1 * p2) / np.sqrt(p1 * p2 * (1 - p1) * (1 - p2) / obs)\n",
    "            pt_p    = 2 * (1 - norm.cdf(abs(pt_stat)))\n",
    "\n",
    "            metrics.append({\n",
    "                \"window\": W, \"top_N\": N, \"method\": method, \"obs\": obs,\n",
    "                \"RMSE_smart\": rmse_s, \"RMSE_median\": rmse_m,\n",
    "                \"HitRate\": hit_rate, \"Binom_p\": binom_p,\n",
    "                \"PT_stat\": pt_stat, \"PT_p\": pt_p, \"DM_p\": dm_p\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "for name, pdf in PANELS.items():\n",
    "    tbl = (evaluate_panel(pdf, name)\n",
    "           .sort_values([\"window\", \"top_N\", \"method\"])\n",
    "           .reset_index(drop=True))\n",
    "    print(f\"\\n--- {name} : Top-N ensemble (mean vs inv_mse) ---\")\n",
    "    print(tbl.to_string(index=False))\n",
    "\n",
    "### Beta version: Let's listen only to forecasters that reacted to the ADP print\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# “Fresh-update” ensemble:\n",
    "# • keep only forecasts with |asof − release_date| ≤ 3 days\n",
    "# • smart forecasts:   mean  &  median   of those “fresh” forecasts\n",
    "# • three directional signals:\n",
    "#       pred_dir_mean   (mean > crowd median)\n",
    "#       pred_dir_med    (median > crowd median)\n",
    "#       pred_dir_vote   (majority of fresh forecasters above crowd median)\n",
    "# • evaluation on realised months\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "import numpy as np, pandas as pd, warnings\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import norm, binomtest\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "PANELS = {\n",
    "    \"Full panel\"          : df_full,   # assume in memory\n",
    "    \"COVID-filtered panel\": df\n",
    "}\n",
    "\n",
    "def evaluate_fresh(panel: pd.DataFrame, label: str) -> pd.DataFrame:\n",
    "    # ±3-day mask (absolute difference ≤ 3 days)\n",
    "    panel = panel.copy()\n",
    "    panel[\"asof_delta\"] = (panel[\"release_date\"] - panel[\"asof\"]).abs().dt.days\n",
    "    panel[\"is_fresh\"]   = panel[\"asof_delta\"] <= 3\n",
    "\n",
    "    dates   = np.sort(panel[\"release_date\"].unique())\n",
    "    rows    = []\n",
    "\n",
    "    for t in tqdm(dates, desc=label):\n",
    "        month_all   = panel[panel[\"release_date\"] == t]\n",
    "        month_fresh = month_all[month_all[\"is_fresh\"]]\n",
    "\n",
    "        if month_fresh.empty:        # no qualifying forecasts\n",
    "            continue\n",
    "\n",
    "        crowd_med = month_all[\"forecast\"].dropna().median()\n",
    "        smart_mean = month_fresh[\"forecast\"].mean()\n",
    "        smart_med  = month_fresh[\"forecast\"].median()\n",
    "\n",
    "        # individual vote: 1 if their forecast > crowd median\n",
    "        voter_flags = (month_fresh[\"forecast\"] > crowd_med).astype(int)\n",
    "        pred_dir_vote = int(voter_flags.mean() > 0.5)   # strict majority\n",
    "\n",
    "        # level-based directions\n",
    "        pred_dir_mean = int(smart_mean > crowd_med)\n",
    "        pred_dir_med  = int(smart_med  > crowd_med)\n",
    "\n",
    "        actual = month_all[\"actual\"].iloc[0]\n",
    "\n",
    "        rows.append((t, smart_mean, smart_med, crowd_med, actual,\n",
    "                     pred_dir_mean, pred_dir_med, pred_dir_vote))\n",
    "\n",
    "    cols = [\"date\",\"smart_mean\",\"smart_med\",\"crowd_median\",\"actual\",\n",
    "            \"dir_mean\",\"dir_med\",\"dir_vote\"]\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "    eval_df = df.dropna(subset=[\"actual\"])\n",
    "    if eval_df.empty:\n",
    "        return pd.DataFrame()       # nothing to score\n",
    "\n",
    "    # errors versus actual\n",
    "    eval_df[\"err_mean\"] = eval_df[\"smart_mean\"] - eval_df[\"actual\"]\n",
    "    eval_df[\"err_med\"]  = eval_df[\"smart_med\"]  - eval_df[\"actual\"]\n",
    "    eval_df[\"err_crowd\"]= eval_df[\"crowd_median\"] - eval_df[\"actual\"]\n",
    "\n",
    "    # helper for directional metrics\n",
    "    def dir_metrics(flag_col):\n",
    "        hits = (eval_df[flag_col] == (eval_df[\"actual\"] > eval_df[\"crowd_median\"]).astype(int)).sum()\n",
    "        hit_rate = hits / len(eval_df)\n",
    "        binom_p  = binomtest(hits, len(eval_df), 0.5).pvalue\n",
    "        p1, p2 = eval_df[flag_col].mean(), (eval_df[\"actual\"] > eval_df[\"crowd_median\"]).mean()\n",
    "        joint  = (eval_df[flag_col].astype(int) &\n",
    "                  (eval_df[\"actual\"] > eval_df[\"crowd_median\"]).astype(int)).mean()\n",
    "        pt_stat = (joint - p1*p2) / np.sqrt(p1*p2*(1-p1)*(1-p2)/len(eval_df))\n",
    "        pt_p    = 2*(1 - norm.cdf(abs(pt_stat)))\n",
    "        return hit_rate, binom_p, pt_stat, pt_p\n",
    "\n",
    "    rmse_mean = np.sqrt((eval_df[\"err_mean\"]**2).mean())\n",
    "    rmse_med  = np.sqrt((eval_df[\"err_med\"]**2 ).mean())\n",
    "    rmse_crowd= np.sqrt((eval_df[\"err_crowd\"]**2).mean())\n",
    "\n",
    "    # Diebold-Mariano (smart_mean vs crowd median)\n",
    "    diff_mean = eval_df[\"err_mean\"]**2 - eval_df[\"err_crowd\"]**2\n",
    "    dm_p_mean = 2*(1 - norm.cdf(abs(diff_mean.mean()/diff_mean.std(ddof=1) *\n",
    "                                     np.sqrt(len(eval_df)))))\n",
    "\n",
    "    # Diebold-Mariano (smart_med vs crowd median)\n",
    "    diff_med  = eval_df[\"err_med\"]**2 - eval_df[\"err_crowd\"]**2\n",
    "    dm_p_med  = 2*(1 - norm.cdf(abs(diff_med.mean()/diff_med.std(ddof=1) *\n",
    "                                     np.sqrt(len(eval_df)))))\n",
    "\n",
    "    # directional stats\n",
    "    hit_mn, bin_mn, pt_mn, ptp_mn = dir_metrics(\"dir_mean\")\n",
    "    hit_md, bin_md, pt_md, ptp_md = dir_metrics(\"dir_med\")\n",
    "    hit_vt, bin_vt, pt_vt, ptp_vt = dir_metrics(\"dir_vote\")\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        \"obs\": len(eval_df),\n",
    "        \"RMSE_mean\":   rmse_mean,\n",
    "        \"RMSE_medianSmart\": rmse_med,\n",
    "        \"RMSE_crowdMedian\": rmse_crowd,\n",
    "        \"DM_p_mean\":   dm_p_mean,\n",
    "        \"DM_p_medianSmart\": dm_p_med,\n",
    "        # directional metrics\n",
    "        \"HitRate_mean\": hit_mn,   \"Binom_p_mean\": bin_mn, \"PT_p_mean\": ptp_mn,\n",
    "        \"HitRate_med\":  hit_md,   \"Binom_p_med\":  bin_md, \"PT_p_med\":  ptp_md,\n",
    "        \"HitRate_vote\": hit_vt,   \"Binom_p_vote\": bin_vt, \"PT_p_vote\": ptp_vt\n",
    "    }])\n",
    "\n",
    "# ---------- run & display ----------\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "for name, pdf in PANELS.items():\n",
    "    tbl = evaluate_fresh(pdf, name)\n",
    "    print(f\"\\n--- {name} : 3-day fresh-update ensemble ---\")\n",
    "    if tbl.empty:\n",
    "        print(\"No months qualified (no fresh forecasts found).\")\n",
    "    else:\n",
    "        print(tbl.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389a2c6",
   "metadata": {},
   "source": [
    "## 0: Baseline static forecast on full sample\n",
    "\n",
    "Rolling 6-month fixed window. For every valid economist (for a prediction at time t, has a contiguous 6-month forecast history for previous 6 releases), weight prediction by inverse MSE. \n",
    "\n",
    "\n",
    "This implements an out-of-sample error estimate with a rolling 6-month estimation window. Weights don't use information from the target month and actual value at month *t* is unseen. In other words, all errors are \"live\" errors that could have been observed in real time.\n",
    "\n",
    "Briefly, the procedure: \n",
    "1. Starts at 7th release (for 6 month release prior)\n",
    "2. From estimation window, keep economists that supplied a forecast for all six months (per contiguity rule)\n",
    "3. Compute MSE for each economist using errors against already known actuals (no lookahead)\n",
    "4. Generate forecast for release t \n",
    "5. Store OOS evaluation error\n",
    "6. Roll window forward a month and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a146b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old smart code that that does ensemble averaging rather than majority vote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e053a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # in-sample, done via smart forecast averaging \n",
    "\n",
    "# # -------------------------------------------------------------\n",
    "# # Majority‑vote ensemble search  (k = 3, 5)\n",
    "# #   • choose best combo on  FULL, trailing‑24 m, trailing‑12 m\n",
    "# #   • show full stratified directional diagnostics\n",
    "# #   • finish with a summary table + majority “verdict”\n",
    "# # -------------------------------------------------------------\n",
    "\n",
    "# # ──────────────────────  SETTINGS  ────────────────────────────\n",
    "# TODAY   = pd.Timestamp.today().normalize()\n",
    "# WINDOWS = {\n",
    "#     \"FULL\" : None,\n",
    "#     \"T24M\" : TODAY - pd.DateOffset(months=24),\n",
    "#     \"T12M\" : TODAY - pd.DateOffset(months=12),\n",
    "#     \"T6M\" : TODAY - pd.DateOffset(months=6),\n",
    "# }\n",
    "\n",
    "# # REGIMES was defined earlier; re‑use the same dict.\n",
    "# # If not present in your notebook, paste the REGIMES definition here.\n",
    "\n",
    "# # ─────────── 1) candidate pool (unchanged)  ───────────────────\n",
    "# pool = set()\n",
    "# for model_id, panel_map in eval_tables.items():\n",
    "#     for panel in [\"COVID\", \"Full\"]:\n",
    "#         df = panel_map.get(panel)\n",
    "#         if df is None or df.empty:\n",
    "#             continue\n",
    "#         pool.add(df.loc[df[\"RMSE_smart\"].idxmin(), \"spec_id\"])  # lowest RMSE\n",
    "#         pool.add(df.loc[df[\"HitRate\"].idxmax(),    \"spec_id\"])  # highest HR\n",
    "#         rob = df[(df[\"DM_p\"] < .10) & (df[\"PT_p\"] < .10)]\n",
    "#         if not rob.empty:\n",
    "#             pool.add(rob.loc[rob[\"RMSE_smart\"].idxmin(), \"spec_id\"])\n",
    "\n",
    "# pool = sorted(pool)\n",
    "# print(f\"Total unique candidate specs selected: {len(pool)}\")\n",
    "\n",
    "# # ─────────── 2) collect FULL‑panel OOS frames  ────────────────\n",
    "# oos_full = {}\n",
    "# for mdl, panel_map in oos_maps.items():\n",
    "#     oos_full.update(panel_map.get(\"Full\", {}))\n",
    "\n",
    "# pool = [s for s in pool if s in oos_full]\n",
    "# assert len(pool) >= 3, \"Need ≥3 viable specs with Full‑panel OOS\"\n",
    "# print(f\"Usable specs with Full‑panel OOS: {len(pool)}\\n\")\n",
    "\n",
    "# # ─────────── 3) helpers  ──────────────────────────────────────\n",
    "# def merged_oos(combo):\n",
    "#     \"\"\"Return merged DataFrame (ens, median, actual) for entire history.\"\"\"\n",
    "#     k   = len(combo)\n",
    "#     dfs = []\n",
    "#     for i, sid in enumerate(combo):\n",
    "#         tmp = (oos_full[sid][[\"date\", \"smart\", \"median\", \"actual\"]]\n",
    "#                .rename(columns={\"smart\":  f\"smart_{i}\",\n",
    "#                                 \"median\": f\"median_{i}\",\n",
    "#                                 \"actual\": f\"actual_{i}\"}))\n",
    "#         dfs.append(tmp)\n",
    "#     df = dfs[0]\n",
    "#     for d in dfs[1:]:\n",
    "#         df = df.merge(d, on=\"date\")\n",
    "\n",
    "#     df[\"median\"] = df[\"median_0\"]\n",
    "#     df[\"actual\"] = df[\"actual_0\"]\n",
    "#     df[\"ens\"]    = df[[f\"smart_{i}\" for i in range(k)]].mean(axis=1)\n",
    "#     return df[[\"date\", \"ens\", \"median\", \"actual\"]]\n",
    "\n",
    "# def dir_metrics(df):\n",
    "#     \"\"\"Directional hit‑rate + Binom/PT p‑values on realised part of df.\"\"\"\n",
    "#     realised = df.dropna(subset=[\"actual\"]).copy()\n",
    "#     realised[\"pred_dir\"]   = (realised[\"ens\"]    > realised[\"median\"]).astype(int)\n",
    "#     realised[\"actual_dir\"] = (realised[\"actual\"] > realised[\"median\"]).astype(int)\n",
    "\n",
    "#     hits = (realised[\"pred_dir\"] == realised[\"actual_dir\"]).sum()\n",
    "#     n    = len(realised)\n",
    "#     if n == 0:\n",
    "#         return np.nan, n, np.nan, np.nan\n",
    "#     hr   = hits / n\n",
    "#     binom_p = stats.binomtest(hits, n, .5).pvalue\n",
    "#     p1, p2  = realised[\"pred_dir\"].mean(), realised[\"actual_dir\"].mean()\n",
    "#     c_joint = (realised[\"pred_dir\"] & realised[\"actual_dir\"]).mean()\n",
    "#     pt_p = 2 * (1 - stats.norm.cdf(abs((c_joint - p1*p2) /\n",
    "#                                        np.sqrt(p1*p2*(1-p1)*(1-p2)/n))))\n",
    "#     return hr, n, binom_p, pt_p\n",
    "\n",
    "# def stratified_table(df):\n",
    "#     rows = []\n",
    "#     for lbl, (start, end) in REGIMES.items():\n",
    "#         sub = df[(df[\"date\"] >= start) & (df[\"date\"] <= end)]\n",
    "#         hr, n, bp, pt = dir_metrics(sub)\n",
    "#         if np.isnan(hr):\n",
    "#             continue\n",
    "#         rows.append({\"Regime\": lbl, \"Obs\": n,\n",
    "#                      \"HitRate\": hr, \"Binom_p\": bp, \"PT_p\": pt})\n",
    "#     return pd.DataFrame(rows)\n",
    "\n",
    "# # ─────────── 4) exhaustive search for k = 3 and 5  ────────────\n",
    "# summary_rows  = []   # for final table\n",
    "# verdict_votes = []   # collect live “Beat/Miss” signals\n",
    "\n",
    "# for k in (3, 5):\n",
    "#     if len(pool) < k:\n",
    "#         print(f\"Skipping k={k}: pool too small\\n\")\n",
    "#         continue\n",
    "\n",
    "#     combos_k = list(itertools.combinations(pool, k))\n",
    "\n",
    "#     for win_lbl, start_date in WINDOWS.items():\n",
    "#         best = {\"combo\": None, \"hr\": -np.inf, \"n\": None,\n",
    "#                 \"binom\": np.nan, \"pt\": np.nan,\n",
    "#                 \"median_live\": np.nan, \"signal\": \"n/a\",\n",
    "#                 \"df_full\": None}\n",
    "\n",
    "#         for combo in combos_k:\n",
    "#             df_all = merged_oos(combo)\n",
    "#             # window‑restricted view for choosing winner\n",
    "#             df_eval = df_all if start_date is None else df_all[df_all[\"date\"] >= start_date]\n",
    "#             hr, n, bp, pt = dir_metrics(df_eval)\n",
    "#             if hr > best[\"hr\"]:\n",
    "#                 # live month info\n",
    "#                 unreleased = df_all[df_all[\"actual\"].isna()].sort_values(\"date\")\n",
    "#                 if not unreleased.empty:\n",
    "#                     last = unreleased.iloc[-1]\n",
    "#                     signal = \"Beat\" if last[\"ens\"] > last[\"median\"] else \"Miss\"\n",
    "#                     median_live = last[\"median\"]\n",
    "#                 else:\n",
    "#                     signal, median_live = \"n/a\", np.nan\n",
    "\n",
    "#                 best.update({\"combo\": combo, \"hr\": hr, \"n\": n,\n",
    "#                              \"binom\": bp, \"pt\": pt,\n",
    "#                              \"median_live\": median_live, \"signal\": signal,\n",
    "#                              \"df_full\": df_all})\n",
    "\n",
    "#         # ── print detailed results ───────────────────────────\n",
    "#         print(f\"[{win_lbl}]  Best ensemble  k={k}\")\n",
    "#         print(f\"  Specs        : {best['combo']}\")\n",
    "#         print(f\"  HitRate      : {best['hr']:.2%}  over {best['n']} months\")\n",
    "#         print(f\"  Binom p‑val  : {best['binom']:.3f}   PT p‑val : {best['pt']:.3f}\")\n",
    "#         if best[\"signal\"] != \"n/a\":\n",
    "#             print(f\"  Consensus med: {best['median_live']:.0f} k\")\n",
    "#         print(f\"  Live signal  : {best['signal']}\")\n",
    "\n",
    "#         # stratified across FULL history (not limited to window)\n",
    "#         st = stratified_table(best[\"df_full\"])\n",
    "#         if st.empty:\n",
    "#             print(\"  Stratified: no realised data yet.\\n\")\n",
    "#         else:\n",
    "#             print(\"  Stratified performance:\")\n",
    "#             print(st.to_string(index=False, float_format=lambda x: f\"{x:0.3f}\"))\n",
    "#             print()\n",
    "\n",
    "#         # gather for summary / verdict\n",
    "#         summary_rows.append({\n",
    "#             \"Window\": win_lbl, \"k\": k,\n",
    "#             \"Specs\": best[\"combo\"],\n",
    "#             \"HitRate\": best[\"hr\"], \"Obs\": best[\"n\"],\n",
    "#             \"Binom_p\": best[\"binom\"], \"PT_p\": best[\"pt\"],\n",
    "#             \"LiveSignal\": best[\"signal\"]\n",
    "#         })\n",
    "#         verdict_votes.append(best[\"signal\"])\n",
    "\n",
    "# # ─────────── 5) summary table & final verdict  ────────────────\n",
    "# summary_df = (pd.DataFrame(summary_rows)\n",
    "#               .sort_values([\"Window\", \"k\"])\n",
    "#               .reset_index(drop=True))\n",
    "# pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "# print(\"\\n================  ENSEMBLE SUMMARY  ================\\n\")\n",
    "# print(summary_df.to_string(index=False))\n",
    "\n",
    "# # majority vote across the six “best” ensembles (ties → ‘No consensus’)\n",
    "# valid_votes = [v for v in verdict_votes if v in (\"Beat\", \"Miss\")]\n",
    "# if valid_votes:\n",
    "#     beat_count = valid_votes.count(\"Beat\")\n",
    "#     miss_count = valid_votes.count(\"Miss\")\n",
    "#     if beat_count > miss_count:\n",
    "#         verdict = \"Beat\"\n",
    "#     elif miss_count > beat_count:\n",
    "#         verdict = \"Miss\"\n",
    "#     else:\n",
    "#         verdict = \"No consensus\"\n",
    "# else:\n",
    "#     verdict = \"No live signal available\"\n",
    "\n",
    "# print(f\"\\n>>> FINAL VERDICT (majority across ensembles):  {verdict}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6630c06f",
   "metadata": {},
   "source": [
    "Old ensemble dynamic backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PATCH: ensure hit is integer, then rebuild the summaries ---\n",
    "summary_rows, strat_tables = [], {}\n",
    "\n",
    "for tag, recs in records.items():\n",
    "    # cast \"hit\" to int so binomtest gets integers\n",
    "    dfp = (pd.DataFrame(recs)\n",
    "             .dropna(subset=[\"hit\"])\n",
    "             .assign(hit       = lambda d: d[\"hit\"].astype(int),\n",
    "                     pred_dir  = lambda d: d[\"pred_dir\"].astype(int),\n",
    "                     actual_dir= lambda d: d[\"actual_dir\"].astype(int)))\n",
    "\n",
    "    ov_hr = dfp[\"hit\"].mean() if not dfp.empty else math.nan\n",
    "    strat = _stratified(dfp) if not dfp.empty else pd.DataFrame()\n",
    "    ac    = _ac_score(ov_hr, strat[\"HitRate\"], LAMBDA_AC) if not strat.empty else math.nan\n",
    "    if not strat.empty:\n",
    "        strat_tables[tag] = strat\n",
    "\n",
    "    summary_rows.append(\n",
    "        dict(Method=tag, Obs=len(dfp), HitRate=ov_hr, **{f\"ACλ={LAMBDA_AC}\": ac})\n",
    "    )\n",
    "\n",
    "# ---------- (same printing / plotting block as before) ----------\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "print(\"\\n=== Back‑test summary (2017‑‑) ===\")\n",
    "print(pd.DataFrame(summary_rows).to_string(index=False))\n",
    "\n",
    "for tag, tbl in strat_tables.items():\n",
    "    print(f\"\\n--- Stratified diagnostics for {tag} ---\")\n",
    "    print(tbl.to_string(index=False, float_format=lambda x: f\"{x:0.3f}\"))\n",
    "    ac_val = next(r[f\"ACλ={LAMBDA_AC}\"] for r in summary_rows if r[\"Method\"] == tag)\n",
    "    print(f\"Accuracy × Consistency (λ = {LAMBDA_AC}):  {ac_val:0.3f}\\n\")\n",
    "\n",
    "print(\"\\n==============  Summary Table  ==============\")\n",
    "print(pd.DataFrame(summary_rows)\n",
    "        .set_index(\"Method\")\n",
    "        .to_string(float_format=lambda x: f\"{x:0.3f}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- evolution plot -------------------------------------------------\n",
    "plt.figure(figsize=(8,4))\n",
    "for tag, pts in sel_hr_ts.items():\n",
    "    if not pts:               # skip empty series\n",
    "        continue\n",
    "    dates, h = zip(*pts)\n",
    "    plt.plot(dates, h, label=tag)\n",
    "plt.title(\"Rolling hit‑rate of winning MV ensemble\")\n",
    "plt.ylabel(\"Hit‑rate\")\n",
    "plt.xlabel(\"Release date\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "#  Dynamic majority‑vote ensembles   (2017‑01 → present)\n",
    "#    • trailing‑window winners  T3 / T6 / T12 / T24\n",
    "#    • Best‑to‑Date (BTD) single‑spec benchmark\n",
    "#    • Accuracy × Consistency score per method (λ = 1.0)\n",
    "#    • Stratified diagnostics: 2017‑19 / 2020‑22 / 2023‑‑\n",
    "#    • Evolution plot of winner hit‑rate (five lines)\n",
    "# ==============================================================\n",
    "\n",
    "import itertools, math, warnings, matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------- configuration ------------------------------------\n",
    "EVAL_START = pd.Timestamp(\"2010-01-01\")            # first forecast recorded\n",
    "WINDOWS    = {3: \"T3\", 6: \"T6\", 12: \"T12\", 24: \"T24\"}\n",
    "K_SET      = (3, 5)                                # ensemble sizes\n",
    "ALPHA      = 0.10                                  # robust‑winner p‑value\n",
    "LAMBDA_AC  = 1.0                                   # weight in A×C score\n",
    "\n",
    "REGIMES = {\n",
    "    \"Post-GFC (2010-14)\": (pd.Timestamp(\"2010-01-01\"),\n",
    "                            pd.Timestamp(\"2014-12-31\")),\n",
    "    \"Late expansion (2015-2019)\": (pd.Timestamp(\"2015-01-01\"),\n",
    "                            pd.Timestamp(\"2019-12-31\")),\n",
    "    \"COVID (2020‑22)\"    : (pd.Timestamp(\"2020-01-01\"),\n",
    "                            pd.Timestamp(\"2022-12-31\")),\n",
    "    \"Post‑COVID (2023‑‑)\": (pd.Timestamp(\"2023-01-01\"),\n",
    "                            pd.Timestamp.today()),\n",
    "}\n",
    "\n",
    "# ---------- helper functions ---------------------------------\n",
    "def _spec_metrics(oos: pd.DataFrame) -> Dict[str, Any]:\n",
    "    df = oos.dropna(subset=[\"actual\"]).copy()\n",
    "    if df.empty:\n",
    "        return dict(obs=0, rmse=np.nan, hr=np.nan, dm_p=np.nan, pt_p=np.nan)\n",
    "\n",
    "    df[\"smart_err\"]  = df[\"smart\"]  - df[\"actual\"]\n",
    "    df[\"median_err\"] = df[\"median\"] - df[\"actual\"]\n",
    "    df[\"pred_dir\"]   = (df[\"smart\"]  > df[\"median\"]).astype(int)\n",
    "    df[\"actual_dir\"] = (df[\"actual\"] > df[\"median\"]).astype(int)\n",
    "\n",
    "    obs  = len(df)\n",
    "    rmse = np.sqrt((df[\"smart_err\"]**2).mean())\n",
    "    hr   = (df[\"pred_dir\"] == df[\"actual_dir\"]).mean()\n",
    "\n",
    "    diff = df[\"smart_err\"]**2 - df[\"median_err\"]**2\n",
    "    dm_p = 1.0 if diff.std(ddof=1) == 0 else \\\n",
    "           2*(1-stats.norm.cdf(abs(diff.mean()/diff.std(ddof=1)*np.sqrt(obs))))\n",
    "\n",
    "    p1, p2 = df[\"pred_dir\"].mean(), df[\"actual_dir\"].mean()\n",
    "    denom  = p1*p2*(1-p1)*(1-p2)\n",
    "    pt_p   = 1.0 if denom == 0 else \\\n",
    "             2*(1-stats.norm.cdf(abs(((df[\"pred_dir\"] & df[\"actual_dir\"]).mean()-p1*p2) /\n",
    "                                     np.sqrt(denom/obs))))\n",
    "\n",
    "    return dict(obs=obs, rmse=rmse, hr=hr, dm_p=dm_p, pt_p=pt_p)\n",
    "\n",
    "\n",
    "def _candidate_pool(stats_df: pd.DataFrame) -> List[str]:\n",
    "    chosen = set()\n",
    "    for (_, _), grp in stats_df.groupby([\"model\", \"panel\"]):\n",
    "        grp = grp[grp[\"obs\"] > 0]\n",
    "        if grp.empty:\n",
    "            continue\n",
    "        chosen.add(grp.loc[grp[\"rmse\"].idxmin(), \"spec_id\"])   # lowest RMSE\n",
    "        chosen.add(grp.loc[grp[\"hr\"].idxmax(),   \"spec_id\"])   # highest HR\n",
    "        rob = grp[(grp[\"dm_p\"] < ALPHA) & (grp[\"pt_p\"] < ALPHA)]\n",
    "        if not rob.empty:\n",
    "            chosen.add(rob.loc[rob[\"rmse\"].idxmin(), \"spec_id\"])\n",
    "    return sorted(chosen)\n",
    "\n",
    "\n",
    "_combo_cache: Dict[Tuple[str, ...], pd.DataFrame] = {}\n",
    "def _merged_oos_cached(combo: Tuple[str, ...]) -> pd.DataFrame:\n",
    "    if combo not in _combo_cache:\n",
    "        _combo_cache[combo] = merged_oos(combo)     # requires earlier cells\n",
    "    return _combo_cache[combo]\n",
    "\n",
    "\n",
    "def _mv_hitrate(df: pd.DataFrame) -> float:\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "    smart_cols = [c for c in df.columns if c.startswith(\"smart_\")]\n",
    "    votes      = (df[smart_cols].gt(df[\"median\"], axis=0)).sum(axis=1)\n",
    "    pred_dir   = (votes > len(smart_cols)/2).astype(int)\n",
    "    actual_dir = (df[\"actual\"] > df[\"median\"]).astype(int)\n",
    "    return (pred_dir == actual_dir).mean()\n",
    "\n",
    "\n",
    "def _combo_hitrate(combo, t_cut, window):\n",
    "    df = _merged_oos_cached(combo)\n",
    "    sub = df[(df[\"date\"] >= t_cut - pd.DateOffset(months=window)) &\n",
    "             (df[\"date\"] <  t_cut) & df[\"actual\"].notna()]\n",
    "    return _mv_hitrate(sub), len(sub)\n",
    "\n",
    "\n",
    "def _window_rmse(combo, t_cut, window):\n",
    "    df = _merged_oos_cached(combo)\n",
    "    sub = df[(df[\"date\"] >= t_cut - pd.DateOffset(months=window)) &\n",
    "             (df[\"date\"] <  t_cut) & df[\"actual\"].notna()]\n",
    "    return (np.inf if sub.empty else np.sqrt(((sub[\"ens\"]-sub[\"actual\"])**2).mean()))\n",
    "\n",
    "\n",
    "def _choose_best_combo(pool, t_cut, window):\n",
    "    best_combo, best_hr, best_rmse = None, -1.0, np.inf\n",
    "    for k in K_SET:\n",
    "        if len(pool) < k:\n",
    "            continue\n",
    "        for combo in itertools.combinations(pool, k):\n",
    "            hr, _ = _combo_hitrate(combo, t_cut, window)\n",
    "            if math.isnan(hr):\n",
    "                continue\n",
    "            if hr > best_hr:\n",
    "                best_combo, best_hr = combo, hr\n",
    "                best_rmse = _window_rmse(combo, t_cut, window)\n",
    "            elif hr == best_hr:\n",
    "                rmse = _window_rmse(combo, t_cut, window)\n",
    "                if rmse < best_rmse or (rmse == best_rmse and combo < best_combo):\n",
    "                    best_combo, best_rmse = combo, rmse\n",
    "    return best_combo, best_hr\n",
    "\n",
    "\n",
    "def _ensemble_direction_mv(combo, t_date):\n",
    "    df = _merged_oos_cached(combo)\n",
    "    row = df[df[\"date\"] == t_date].iloc[0]\n",
    "    smart_cols = [c for c in row.index if c.startswith(\"smart_\")]\n",
    "    votes = sum(row[c] > row[\"median\"] for c in smart_cols)\n",
    "    return int(votes > len(smart_cols)/2)\n",
    "\n",
    "\n",
    "def _actual_direction(any_spec_df, t_date):\n",
    "    row = any_spec_df[any_spec_df[\"date\"] == t_date].iloc[0]\n",
    "    return int(row[\"actual\"] > row[\"median\"])\n",
    "\n",
    "\n",
    "def _stratified(df_preds: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for lbl, (s, e) in REGIMES.items():\n",
    "        sub = df_preds[(df_preds[\"date\"] >= s) & (df_preds[\"date\"] <= e)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        hits = sub[\"hit\"].mean()\n",
    "        n    = len(sub)\n",
    "        binom = stats.binomtest(sub[\"hit\"].sum(), n, .5).pvalue\n",
    "        p1, p2 = sub[\"pred_dir\"].mean(), sub[\"actual_dir\"].mean()\n",
    "        denom  = p1*p2*(1-p1)*(1-p2)\n",
    "        pt     = 1.0 if denom == 0 else \\\n",
    "                 2*(1-stats.norm.cdf(abs(((sub[\"pred_dir\"] & sub[\"actual_dir\"]).mean()-p1*p2) /\n",
    "                                         math.sqrt(denom/n))))\n",
    "        rows.append(dict(Regime=lbl, Obs=n, HitRate=hits, Binom_p=binom, PT_p=pt))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def _ac_score(overall_hr, reg_hits, lam=LAMBDA_AC):\n",
    "    if len(reg_hits) < 2 or math.isnan(overall_hr):\n",
    "        return np.nan\n",
    "    return (1 - overall_hr) + lam*np.std(reg_hits, ddof=1)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. timeline + warm‑up discovery (≥24 realised obs)\n",
    "# -------------------------------------------------------------\n",
    "all_dates = sorted({pd.to_datetime(d)\n",
    "                    for mdl in oos_maps.values()\n",
    "                    for pnl in mdl.values()\n",
    "                    for o in pnl.values()\n",
    "                    for d in o[\"date\"].unique()})\n",
    "\n",
    "warmup_idx = 0\n",
    "with tqdm(total=len(all_dates), desc=\"Finding warm‑up start\") as bar:\n",
    "    while warmup_idx < len(all_dates) and all_dates[warmup_idx] < EVAL_START:\n",
    "        warmup_idx += 1\n",
    "        bar.update(1)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. rolling evaluation\n",
    "# -------------------------------------------------------------\n",
    "records   = {tag: [] for tag in WINDOWS.values()}\n",
    "records[\"BTD\"] = []\n",
    "sel_hr_ts = {tag: [] for tag in list(WINDOWS.values()) + [\"BTD\"]}\n",
    "\n",
    "# helpers for BTD\n",
    "cum_hits: Dict[str, int] = defaultdict(int)\n",
    "cum_obs : Dict[str, int] = defaultdict(int)\n",
    "\n",
    "dates_iter = tqdm(all_dates[warmup_idx:], desc=\"Rolling evaluation\", unit=\"month\")\n",
    "sample_oos_any = next(iter(oos_maps[next(iter(oos_maps))][\"Full\"].values()))\n",
    "\n",
    "for t in dates_iter:\n",
    "    if t < EVAL_START:\n",
    "        continue\n",
    "\n",
    "    # --- per‑spec metrics through t‑1 -----------------------\n",
    "    rows_stats = []\n",
    "    for m_id, pnl_map in oos_maps.items():\n",
    "        for p_name, spec_dict in pnl_map.items():\n",
    "            for sid, oos in spec_dict.items():\n",
    "                met = _spec_metrics(oos[oos[\"date\"] < t])\n",
    "                met.update(model=m_id, panel=p_name, spec_id=sid)\n",
    "                rows_stats.append(met)\n",
    "    stats_df = pd.DataFrame(rows_stats)\n",
    "    if stats_df[\"obs\"].max() < 12:\n",
    "        continue\n",
    "\n",
    "    # --- candidate pool -------------------------------------\n",
    "    pool_t = _candidate_pool(stats_df)\n",
    "    if len(pool_t) < 3:\n",
    "        continue\n",
    "\n",
    "    # --- choose MV winners per window -----------------------\n",
    "    best_combo: Dict[str, Tuple[str, ...]] = {}\n",
    "    win_hr     : Dict[str, float]          = {}\n",
    "\n",
    "    for W in WINDOWS:\n",
    "        combo, hr = _choose_best_combo(pool_t, t, W)\n",
    "        if combo:\n",
    "            tag = WINDOWS[W]\n",
    "            best_combo[tag] = combo\n",
    "            win_hr[tag]     = hr\n",
    "\n",
    "    # --- BTD single‑spec ------------------------------------\n",
    "    for row in stats_df.itertuples():\n",
    "        cum_hits[row.spec_id] = int(row.hr * row.obs)   # store total hits to date\n",
    "        cum_obs [row.spec_id] = row.obs                 # store total obs to date\n",
    "    if cum_obs:\n",
    "        best_sid = max(cum_obs, key=lambda s: cum_hits[s] / cum_obs[s])\n",
    "        best_combo[\"BTD\"] = (best_sid,)\n",
    "        win_hr[\"BTD\"]     = cum_hits[best_sid] / cum_obs[best_sid]\n",
    "\n",
    "    if not best_combo:\n",
    "        continue\n",
    "\n",
    "    # --- actual known? --------------------------------------\n",
    "    actual_known = pd.notna(sample_oos_any.loc[sample_oos_any[\"date\"] == t, \"actual\"].iloc[0])\n",
    "\n",
    "    # --- record predictions & hit‑rate evolution ------------\n",
    "    for tag, combo in best_combo.items():\n",
    "        pred_dir = _ensemble_direction_mv(combo, t)  # works for 1- or many‑member\n",
    "        rec = dict(date=t, pred_dir=pred_dir, sel_hr=win_hr[tag])\n",
    "        if actual_known:\n",
    "            rec[\"actual_dir\"] = _actual_direction(sample_oos_any, t)\n",
    "            rec[\"hit\"]        = int(rec[\"pred_dir\"] == rec[\"actual_dir\"])\n",
    "        records[tag].append(rec)\n",
    "        sel_hr_ts[tag].append((t, win_hr[tag]))\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. summaries, stratified diagnostics, AC score\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# --- PATCH: ensure hit is integer, then rebuild the summaries ---\n",
    "summary_rows, strat_tables = [], {}\n",
    "\n",
    "for tag, recs in records.items():\n",
    "    # cast \"hit\" to int so binomtest gets integers\n",
    "    dfp = (pd.DataFrame(recs)\n",
    "             .dropna(subset=[\"hit\"])\n",
    "             .assign(hit       = lambda d: d[\"hit\"].astype(int),\n",
    "                     pred_dir  = lambda d: d[\"pred_dir\"].astype(int),\n",
    "                     actual_dir= lambda d: d[\"actual_dir\"].astype(int)))\n",
    "\n",
    "    ov_hr = dfp[\"hit\"].mean() if not dfp.empty else math.nan\n",
    "    strat = _stratified(dfp) if not dfp.empty else pd.DataFrame()\n",
    "    ac    = _ac_score(ov_hr, strat[\"HitRate\"], LAMBDA_AC) if not strat.empty else math.nan\n",
    "    if not strat.empty:\n",
    "        strat_tables[tag] = strat\n",
    "\n",
    "    summary_rows.append(\n",
    "        dict(Method=tag, Obs=len(dfp), HitRate=ov_hr, **{f\"ACλ={LAMBDA_AC}\": ac})\n",
    "    )\n",
    "\n",
    "# ---------- (same printing / plotting block as before) ----------\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "print(\"\\n=== Back‑test summary (2017‑‑) ===\")\n",
    "print(pd.DataFrame(summary_rows).to_string(index=False))\n",
    "\n",
    "for tag, tbl in strat_tables.items():\n",
    "    print(f\"\\n--- Stratified diagnostics for {tag} ---\")\n",
    "    print(tbl.to_string(index=False, float_format=lambda x: f\"{x:0.3f}\"))\n",
    "    ac_val = next(r[f\"ACλ={LAMBDA_AC}\"] for r in summary_rows if r[\"Method\"] == tag)\n",
    "    print(f\"Accuracy × Consistency (λ = {LAMBDA_AC}):  {ac_val:0.3f}\\n\")\n",
    "\n",
    "print(\"\\n==============  Summary Table  ==============\")\n",
    "print(pd.DataFrame(summary_rows)\n",
    "        .set_index(\"Method\")\n",
    "        .to_string(float_format=lambda x: f\"{x:0.3f}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools, math\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------------- configuration -----------------------------\n",
    "WINDOWS = {6: \"T6\", 12: \"T12\", 24: \"T24\"}     # trailing windows\n",
    "K_SET   = (3, 5)                     # ensemble sizes\n",
    "ALPHA   = 0.10                       # p‑value threshold for robust winner\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# ---------- helper functions (unchanged except tqdm) --------\n",
    "def _spec_metrics(oos: pd.DataFrame) -> Dict[str, Any]:\n",
    "    df = oos.dropna(subset=[\"actual\"]).copy()\n",
    "    if df.empty:\n",
    "        return {\"obs\": 0, \"rmse\": np.nan, \"hr\": np.nan,\n",
    "                \"dm_p\": np.nan, \"pt_p\": np.nan}\n",
    "\n",
    "    df[\"smart_err\"]  = df[\"smart\"]  - df[\"actual\"]\n",
    "    df[\"median_err\"] = df[\"median\"] - df[\"actual\"]\n",
    "    df[\"actual_dir\"] = (df[\"actual\"] > df[\"median\"]).astype(int)\n",
    "\n",
    "    obs  = len(df)\n",
    "    rmse = np.sqrt((df[\"smart_err\"] ** 2).mean())\n",
    "    hr   = (df[\"pred_dir\"] == df[\"actual_dir\"]).mean()\n",
    "\n",
    "    diff = df[\"smart_err\"] ** 2 - df[\"median_err\"] ** 2\n",
    "    dm_p = (1.0 if diff.std(ddof=1) == 0 else\n",
    "            2 * (1 - stats.norm.cdf(abs(diff.mean() /\n",
    "                                         diff.std(ddof=1) *\n",
    "                                         math.sqrt(obs)))))\n",
    "\n",
    "    p1, p2 = df[\"pred_dir\"].mean(), df[\"actual_dir\"].mean()\n",
    "    denom  = p1 * p2 * (1 - p1) * (1 - p2)\n",
    "    pt_p   = (1.0 if denom == 0 else\n",
    "              2 * (1 - stats.norm.cdf(abs(((df[\"pred_dir\"] &\n",
    "                                             df[\"actual_dir\"]).mean() -\n",
    "                                             p1 * p2) /\n",
    "                                           math.sqrt(denom / obs)))))\n",
    "\n",
    "    return {\"obs\": obs, \"rmse\": rmse, \"hr\": hr, \"dm_p\": dm_p, \"pt_p\": pt_p}\n",
    "\n",
    "\n",
    "def _candidate_pool(stats_df: pd.DataFrame) -> List[str]:\n",
    "    chosen = set()\n",
    "    for (mdl, pnl), grp in stats_df.groupby([\"model\", \"panel\"]):\n",
    "        grp = grp[grp[\"obs\"] > 0]\n",
    "        if grp.empty:\n",
    "            continue\n",
    "        chosen.add(grp.loc[grp[\"rmse\"].idxmin(), \"spec_id\"])\n",
    "        chosen.add(grp.loc[grp[\"hr\"].idxmax(),   \"spec_id\"])\n",
    "        robust = grp[(grp[\"dm_p\"] < ALPHA) & (grp[\"pt_p\"] < ALPHA)]\n",
    "        if not robust.empty:\n",
    "            chosen.add(robust.loc[robust[\"rmse\"].idxmin(), \"spec_id\"])\n",
    "    return sorted(chosen)\n",
    "\n",
    "\n",
    "_combo_cache: Dict[Tuple[str, ...], pd.DataFrame] = {}\n",
    "def _merged_oos_cached(combo: Tuple[str, ...]):\n",
    "    if combo not in _combo_cache:\n",
    "        _combo_cache[combo] = merged_oos(combo)\n",
    "    return _combo_cache[combo]\n",
    "\n",
    "\n",
    "def _combo_hitrate(combo: Tuple[str, ...], t_cut: pd.Timestamp,\n",
    "                   window: int) -> Tuple[float, int]:\n",
    "    df = _merged_oos_cached(combo)\n",
    "    sub = df[(df[\"date\"] >= t_cut - pd.DateOffset(months=window)) &\n",
    "             (df[\"date\"] <  t_cut) & df[\"actual\"].notna()].copy()\n",
    "    if sub.empty:\n",
    "        return np.nan, 0\n",
    "    sub[\"actual_dir\"] = (sub[\"actual\"] > sub[\"median\"]).astype(int)\n",
    "    hr = (sub[\"ens\"] > sub[\"median\"]).eq(sub[\"actual_dir\"]).mean()\n",
    "    return hr, len(sub)\n",
    "\n",
    "\n",
    "def _choose_best_combo(pool: List[str], t_cut: pd.Timestamp,\n",
    "                       window: int) -> Tuple[Tuple[str, ...], float]:\n",
    "    best_combo, best_hr, best_rmse = None, -1.0, np.inf\n",
    "    for k in K_SET:\n",
    "        if len(pool) < k:\n",
    "            continue\n",
    "        for combo in itertools.combinations(pool, k):\n",
    "            hr, _ = _combo_hitrate(combo, t_cut, window)\n",
    "            if math.isnan(hr):\n",
    "                continue\n",
    "            if hr > best_hr:\n",
    "                best_combo, best_hr = combo, hr\n",
    "                best_rmse = _window_rmse(combo, t_cut, window)\n",
    "            elif hr == best_hr:\n",
    "                rmse = _window_rmse(combo, t_cut, window)\n",
    "                if rmse < best_rmse or (rmse == best_rmse and combo < best_combo):\n",
    "                    best_combo, best_rmse = combo, rmse\n",
    "    return best_combo, best_hr\n",
    "\n",
    "\n",
    "def _window_rmse(combo: Tuple[str, ...], t_cut: pd.Timestamp, window: int):\n",
    "    df = _merged_oos_cached(combo)\n",
    "    sub = df[(df[\"date\"] >= t_cut - pd.DateOffset(months=window)) &\n",
    "             (df[\"date\"] <  t_cut) & df[\"actual\"].notna()]\n",
    "    return (np.inf if sub.empty else\n",
    "            math.sqrt(((sub[\"ens\"] - sub[\"actual\"]) ** 2).mean()))\n",
    "\n",
    "\n",
    "def _ensemble_direction(combo: Tuple[str, ...], t_date: pd.Timestamp) -> int:\n",
    "    df = _merged_oos_cached(combo)\n",
    "    row = df[df[\"date\"] == t_date].iloc[0]\n",
    "    return int(row[\"ens\"] > row[\"median\"])\n",
    "\n",
    "\n",
    "def _actual_direction(spec_any: pd.DataFrame, t_date: pd.Timestamp) -> int:\n",
    "    row = spec_any[spec_any[\"date\"] == t_date].iloc[0]\n",
    "    return int(row[\"actual\"] > row[\"median\"])\n",
    "\n",
    "\n",
    "def stratified_table(df_preds: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Directional diagnostics by regime; columns coerced to int.\"\"\"\n",
    "    df = df_preds.copy()\n",
    "    df[\"pred_dir\"]   = df[\"pred_dir\"].astype(int)\n",
    "    df[\"actual_dir\"] = df[\"actual_dir\"].astype(int)\n",
    "\n",
    "    rows = []\n",
    "    for lbl, (start, end) in REGIMES.items():\n",
    "        sub = df[(df[\"date\"] >= start) & (df[\"date\"] <= end)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        hits = (sub[\"pred_dir\"] == sub[\"actual_dir\"]).sum()\n",
    "        n    = len(sub)\n",
    "        hr   = hits / n\n",
    "        binom_p = stats.binomtest(hits, n, .5).pvalue\n",
    "\n",
    "        p1, p2 = sub[\"pred_dir\"].mean(), sub[\"actual_dir\"].mean()\n",
    "        denom  = p1 * p2 * (1 - p1) * (1 - p2)\n",
    "        if denom == 0:\n",
    "            pt_p = 1.0\n",
    "        else:\n",
    "            joint = (sub[\"pred_dir\"].astype(int) & sub[\"actual_dir\"].astype(int)).mean()\n",
    "            pt_stat = (joint - p1 * p2) / math.sqrt(denom / n)\n",
    "            pt_p = 2 * (1 - stats.norm.cdf(abs(pt_stat)))\n",
    "\n",
    "        rows.append({\"Regime\": lbl, \"Obs\": n,\n",
    "                     \"HitRate\": hr, \"Binom_p\": binom_p, \"PT_p\": pt_p})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "# ------------------------------------------------------------\n",
    "# 2.  Timeline & warm‑up discovery\n",
    "# ------------------------------------------------------------\n",
    "all_dates = sorted({pd.to_datetime(d)\n",
    "                    for mdl in oos_maps.values()\n",
    "                    for pnl in mdl.values()\n",
    "                    for o in pnl.values()\n",
    "                    for d in o[\"date\"].unique()})\n",
    "\n",
    "warmup_idx = 0\n",
    "with tqdm(total=len(all_dates), desc=\"Finding warm‑up start\") as pbar:\n",
    "    while warmup_idx < len(all_dates):\n",
    "        t0 = all_dates[warmup_idx]\n",
    "        ok = True\n",
    "        for mdl in oos_maps.values():\n",
    "            for pnl in mdl.values():\n",
    "                for oos in pnl.values():\n",
    "                    realised = oos[(oos[\"date\"] < t0) & oos[\"actual\"].notna()]\n",
    "                    if len(realised) < 24:\n",
    "                        ok = False\n",
    "                        break\n",
    "                if not ok:\n",
    "                    break\n",
    "            if not ok:\n",
    "                break\n",
    "        if ok:\n",
    "            break\n",
    "        warmup_idx += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "print(f\"Warm‑up starts at {all_dates[warmup_idx].date()}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3.  Rolling evaluation with progress bar\n",
    "# ------------------------------------------------------------\n",
    "records = {tag: [] for tag in WINDOWS.values()}\n",
    "dates_iter = tqdm(all_dates[warmup_idx:], desc=\"Rolling evaluation\", unit=\"month\")\n",
    "\n",
    "# pick one oos frame just to fetch actuals quickly\n",
    "sample_oos_any = next(iter(\n",
    "    oos_maps[next(iter(oos_maps))][\"Full\"].values()\n",
    "))\n",
    "\n",
    "for t in dates_iter:\n",
    "    # --- per‑spec stats -------------------------------------\n",
    "    rows_stats = []\n",
    "    for model_id, panel_map in oos_maps.items():\n",
    "        for panel_name, spec_dict in panel_map.items():\n",
    "            for spec_id, oos in spec_dict.items():\n",
    "                metrics = _spec_metrics(oos[oos[\"date\"] < t])\n",
    "                metrics.update({\"model\": model_id,\n",
    "                                \"panel\": panel_name,\n",
    "                                \"spec_id\": spec_id})\n",
    "                rows_stats.append(metrics)\n",
    "    stats_df = pd.DataFrame(rows_stats)\n",
    "    if stats_df[\"obs\"].max() < 12:\n",
    "        continue\n",
    "\n",
    "    # --- candidate pool -------------------------------------\n",
    "    pool_t = _candidate_pool(stats_df)\n",
    "    if len(pool_t) < 3:\n",
    "        continue\n",
    "\n",
    "    # --- choose best combos for each window -----------------\n",
    "    best_combo_dict = {}\n",
    "    for W in WINDOWS:\n",
    "        combo, hr = _choose_best_combo(pool_t, t, W)\n",
    "        if combo is not None:\n",
    "            best_combo_dict[WINDOWS[W]] = combo\n",
    "\n",
    "    if not best_combo_dict:\n",
    "        continue\n",
    "\n",
    "    actual_known = not math.isnan(\n",
    "        sample_oos_any[sample_oos_any[\"date\"] == t][\"actual\"].iloc[0]\n",
    "    )\n",
    "\n",
    "    # --- live predictions & logging -------------------------\n",
    "    for tag, combo in best_combo_dict.items():\n",
    "        pred_dir = _ensemble_direction(combo, t)\n",
    "        rec = {\"date\": t, \"pred_dir\": pred_dir}\n",
    "        if actual_known:\n",
    "            rec[\"actual_dir\"] = _actual_direction(sample_oos_any, t)\n",
    "            rec[\"hit\"] = int(rec[\"pred_dir\"] == rec[\"actual_dir\"])\n",
    "        records[tag].append(rec)\n",
    "\n",
    "# -------------------- build overall summary -----------------------\n",
    "summary_rows, strat_tables = [], {}\n",
    "for tag, recs in records.items():\n",
    "    df_preds = (pd.DataFrame(recs)\n",
    "                  .dropna(subset=[\"hit\"])\n",
    "                  .assign(pred_dir=lambda d: d[\"pred_dir\"].astype(int),\n",
    "                          actual_dir=lambda d: d[\"actual_dir\"].astype(int)))\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"Method\": tag,\n",
    "        \"Obs\": len(df_preds),\n",
    "        \"HitRate\": df_preds[\"hit\"].mean() if not df_preds.empty else np.nan\n",
    "    })\n",
    "\n",
    "    if not df_preds.empty:\n",
    "        strat_tables[tag] = stratified_table(df_preds)\n",
    "\n",
    "print(\"\\n=== Dynamic robust‑ensemble back‑test summary ===\")\n",
    "print(pd.DataFrame(summary_rows)\n",
    "        .to_string(index=False, float_format=lambda x: f\"{x:0.3f}\"))\n",
    "\n",
    "for tag, tbl in strat_tables.items():\n",
    "    print(f\"\\n--- Stratified diagnostics for {tag} ---\")\n",
    "    print(tbl.to_string(index=False, float_format=lambda x: f\"{x:0.3f}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f2b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD MWU\n",
    "def backtest_mwu(\n",
    "    panel: pd.DataFrame,\n",
    "    windows: list[int] = CONT_WINDOWS,\n",
    "    etas:    list[float] = ETA_GRID,\n",
    "    ridge:   float       = RIDGE,\n",
    "    eps:     float       = 0.0          # set to 1e-6 if you want a weight floor\n",
    "):\n",
    "    \"\"\"\n",
    "    Walk-forward grid over (window, eta) for Multiplicative-Weights-Update.\n",
    "    • The active expert set is re-built every step (contiguous W-month history).\n",
    "    • New entrants receive equal prior mass; dropped economists are removed.\n",
    "    • Snapshots for LIVE_WEIGHT_SNAPSHOTS are taken after renormalisation.\n",
    "    Returns: eval_df, live_df, oos_map keyed by spec_id.\n",
    "    \"\"\"\n",
    "    pname     = getattr(panel, \"name\", \"panel\")\n",
    "    dates     = np.sort(panel[\"release_date\"].unique())\n",
    "    # start with an empty weight vector – it will be initialised on first active set\n",
    "    w0        = pd.Series(dtype=float)\n",
    "\n",
    "    eval_rows, live_rows, oos_map = [], [], {}\n",
    "\n",
    "    for W, eta in tqdm(product(windows, etas),\n",
    "                       total=len(windows) * len(etas),\n",
    "                       desc=f\"{pname} grid\"):\n",
    "        spec_id = f\"mwu_w{W}_eta{eta:.3f}\"\n",
    "        w       = w0.copy()          # (re)initialise per spec\n",
    "        w_last  = None\n",
    "        recs    = []\n",
    "\n",
    "        # ---------------- walk-forward ----------------\n",
    "        for idx, d in enumerate(dates):\n",
    "            cur = panel.loc[panel[\"release_date\"] == d]\n",
    "\n",
    "            # 1️⃣ determine economists with *contiguous* history of length W\n",
    "            if idx < W:\n",
    "                active = pd.Index([])\n",
    "            else:\n",
    "                hist = panel.loc[panel[\"release_date\"].isin(dates[idx-W:idx])]\n",
    "                active = (\n",
    "                    hist.groupby(\"economist\")[\"forecast\"]\n",
    "                    .apply(lambda s: len(s) == W and s.notna().all())  # <-- strict check\n",
    "                    .pipe(lambda s: s[s].index)\n",
    "            )\n",
    "\n",
    "            if active.empty:\n",
    "                continue  # nothing to do for this date\n",
    "\n",
    "            # 2️⃣ rebuild / extend the weight vector to the active set\n",
    "            w = w.reindex(active)              # drop inactive, add new\n",
    "            if w.isna().any():                 # give newcomers equal prior\n",
    "                w.fillna(1.0, inplace=True)\n",
    "            if w.sum() == 0.0:                 # all zeros (unlikely, but safe)\n",
    "                w[:] = 1.0\n",
    "            if eps > 0.0:                      # optional floor\n",
    "                w = (w + eps) / (w + eps).sum()\n",
    "            else:\n",
    "                w /= w.sum()\n",
    "\n",
    "            # 3️⃣ form today's forecast if we have ≥2 available economists\n",
    "            f_t   = cur.set_index(\"economist\")[\"forecast\"].reindex(w.index)\n",
    "            avail = f_t.notna()\n",
    "            if avail.sum() >= 2:\n",
    "                w_av   = w[avail].copy()\n",
    "                w_av  /= w_av.sum()\n",
    "                w_last = w_av.copy()           # snapshot before seeing actual\n",
    "                smart  = float(np.dot(w_av, f_t[avail]))\n",
    "                median = float(cur[\"median_forecast\"].iloc[0])\n",
    "                actual = float(cur[\"actual\"].iloc[0])\n",
    "                recs.append((d, smart, median, actual, int(smart > median)))\n",
    "\n",
    "            # 4️⃣ update weights once actual is known\n",
    "            if pd.notna(cur[\"actual\"].iloc[0]):\n",
    "                a_val = cur[\"actual\"].iloc[0]\n",
    "                loss  = (f_t - a_val).pow(2).fillna(0.0) + ridge\n",
    "                w    *= np.exp(-eta * loss)\n",
    "                if w.sum() == 0.0:             # numerical underflow fallback\n",
    "                    w[:] = 1.0\n",
    "                if eps > 0.0:\n",
    "                    w = (w + eps) / (w + eps).sum()\n",
    "                else:\n",
    "                    w /= w.sum()\n",
    "\n",
    "        if not recs:\n",
    "            continue\n",
    "\n",
    "        # ---------------- store results ----------------\n",
    "        oos = pd.DataFrame(recs, columns=[\"date\", \"smart\", \"median\",\n",
    "                                          \"actual\", \"pred_dir\"])\n",
    "        oos_map[spec_id] = oos\n",
    "\n",
    "        # live row + snapshot\n",
    "        last = oos.iloc[-1]\n",
    "        if pd.isna(last[\"actual\"]):\n",
    "            live_rows.append({\n",
    "                \"spec_id\": spec_id, \"panel\": pname,\n",
    "                \"window\":  W,        \"eta\":   eta,\n",
    "                \"date\":    last[\"date\"],\n",
    "                \"smart\":   last[\"smart\"],\n",
    "                \"median\":  last[\"median\"],\n",
    "                \"pred_dir\": last[\"pred_dir\"]\n",
    "            })\n",
    "            if w_last is not None:\n",
    "                snap_meta = {\n",
    "                    \"date\":  last[\"date\"],\n",
    "                    \"panel\": pname,\n",
    "                    \"model\": \"mwu\",\n",
    "                    \"spec\":  spec_id\n",
    "                }\n",
    "                for econ, wt in w_last.items():\n",
    "                    LIVE_WEIGHT_SNAPSHOTS.append(\n",
    "                        {**snap_meta,\n",
    "                         \"economist\": econ,\n",
    "                         \"weight\":    float(wt)}\n",
    "                    )\n",
    "\n",
    "        # realised evaluation\n",
    "        df_eval = oos.dropna(subset=[\"actual\"]).copy()\n",
    "        if df_eval.empty:\n",
    "            continue\n",
    "        df_eval[\"smart_err\"]  = df_eval[\"smart\"]  - df_eval[\"actual\"]\n",
    "        df_eval[\"median_err\"] = df_eval[\"median\"] - df_eval[\"actual\"]\n",
    "        df_eval[\"actual_dir\"] = (df_eval[\"actual\"] > df_eval[\"median\"]).astype(int)\n",
    "\n",
    "        obs      = len(df_eval)\n",
    "        rmse_s   = np.sqrt((df_eval[\"smart_err\"]**2).mean())\n",
    "        rmse_m   = np.sqrt((df_eval[\"median_err\"]**2).mean())\n",
    "        diff     = df_eval[\"smart_err\"]**2 - df_eval[\"median_err\"]**2\n",
    "        dm_p     = 2 * (1 - stats.norm.cdf(abs(diff.mean() /\n",
    "                                               diff.std(ddof=1) * np.sqrt(obs))))\n",
    "        hits     = (df_eval[\"pred_dir\"] == df_eval[\"actual_dir\"]).sum()\n",
    "        hit_rate = hits / obs\n",
    "        binom_p  = stats.binomtest(hits, obs, .5).pvalue\n",
    "        p1, p2   = df_eval[\"pred_dir\"].mean(), df_eval[\"actual_dir\"].mean()\n",
    "        c_joint  = (df_eval[\"pred_dir\"] & df_eval[\"actual_dir\"]).mean()\n",
    "        pt_p     = 2 * (1 - stats.norm.cdf(abs((c_joint - p1*p2) /\n",
    "                                               np.sqrt(p1*p2*(1-p1)*(1-p2)/obs))))\n",
    "\n",
    "        eval_rows.append({\n",
    "            \"spec_id\":     spec_id,\n",
    "            \"panel\":       pname,\n",
    "            \"window\":      W,\n",
    "            \"eta\":         eta,\n",
    "            \"obs\":         obs,\n",
    "            \"RMSE_smart\":  rmse_s,\n",
    "            \"RMSE_median\": rmse_m,\n",
    "            \"SmartBetter\": int(rmse_s < rmse_m),\n",
    "            \"HitRate\":     hit_rate,\n",
    "            \"Binom_p\":     binom_p,\n",
    "            \"PT_p\":        pt_p,\n",
    "            \"DM_p\":        dm_p\n",
    "        })\n",
    "\n",
    "    # ------------- wrap-up -------------\n",
    "    eval_df = pd.DataFrame(eval_rows)\n",
    "    live_df = pd.DataFrame(live_rows)\n",
    "    eval_df[\"model_id\"] = \"mwu\"\n",
    "    live_df[\"model_id\"] = \"mwu\"\n",
    "    return eval_df, live_df, oos_map\n",
    "\n",
    "# ---------------- STRATIFIED DIAGNOSTICS -----------------------\n",
    "def stratified_mwu(oos: pd.DataFrame, regimes=REGIMES) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    df  = oos.dropna(subset=[\"actual\"]).copy()\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df[\"smart_err\"]  = df[\"smart\"]  - df[\"actual\"]\n",
    "    df[\"median_err\"] = df[\"median\"] - df[\"actual\"]\n",
    "    df[\"pred_dir\"]   = (df[\"smart\"] > df[\"median\"]).astype(int)\n",
    "    df[\"actual_dir\"] = (df[\"actual\"] > df[\"median\"]).astype(int)\n",
    "\n",
    "    for lbl, (start, end) in regimes.items():\n",
    "        sub = df[(df[\"date\"] >= start) & (df[\"date\"] <= end)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        obs      = len(sub)\n",
    "        rm_s     = np.sqrt((sub[\"smart_err\"]**2).mean())\n",
    "        rm_m     = np.sqrt((sub[\"median_err\"]**2).mean())\n",
    "        diff     = sub[\"smart_err\"]**2 - sub[\"median_err\"]**2\n",
    "        dm_p     = 2 * (1 - stats.norm.cdf(abs(diff.mean() / diff.std(ddof=1) * np.sqrt(obs))))\n",
    "        hits     = (sub[\"pred_dir\"] == sub[\"actual_dir\"]).sum()\n",
    "        hit_rate = hits / obs\n",
    "        binom_p  = stats.binomtest(hits, obs, .5).pvalue\n",
    "        p1, p2   = sub[\"pred_dir\"].mean(), sub[\"actual_dir\"].mean()\n",
    "        c_joint  = (sub[\"pred_dir\"] & sub[\"actual_dir\"]).mean()\n",
    "        pt_p     = 2 * (1 - stats.norm.cdf(abs((c_joint - p1*p2) /\n",
    "                                               np.sqrt(p1*p2*(1-p1)*(1-p2)/obs))))\n",
    "\n",
    "        rows.append({\n",
    "            \"Regime\":      lbl,\n",
    "            \"Obs\":         obs,\n",
    "            \"RMSE_smart\":  rm_s,\n",
    "            \"RMSE_median\": rm_m,\n",
    "            \"SmartBetter\": int(rm_s < rm_m),\n",
    "            \"HitRate\":     hit_rate,\n",
    "            \"Binom_p\":     binom_p,\n",
    "            \"PT_p\":        pt_p,\n",
    "            \"DM_p\":        dm_p\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --------------------- DRIVER & PRINTING ----------------------\n",
    "for name, pnl in PANELS.items():\n",
    "    pnl.name = name\n",
    "    ev, lv, om = backtest_mwu(pnl)\n",
    "    eval_tables[\"mwu\"][name] = ev\n",
    "    live_tables[\"mwu\"][name] = lv\n",
    "    oos_maps   [\"mwu\"][name] = om\n",
    "    _all_eval.append(ev)\n",
    "    _all_live.append(lv)\n",
    "    if om:\n",
    "        realised = next(iter(om.values())).dropna(subset=[\"actual\"])\n",
    "        actual_dir[\"mwu\"][name] = (realised[\"actual\"] > realised[\"median\"]).astype(int).values\n",
    "    else:\n",
    "        actual_dir[\"mwu\"][name] = np.array([], dtype=int)\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "def print_key_specs_mwu(df: pd.DataFrame, panel_name: str) -> None:\n",
    "    low  = df.loc[df[\"RMSE_smart\"].idxmin()]\n",
    "    high = df.loc[df[\"HitRate\"].idxmax()]\n",
    "    rob  = df[(df[\"DM_p\"] < .10) & (df[\"PT_p\"] < .10)]\n",
    "    if not rob.empty:\n",
    "        r = rob.loc[rob[\"RMSE_smart\"].idxmin()]\n",
    "        rob_str = f\"{r['spec_id']} (w={int(r['window'])}, η={r['eta']:.3f})\"\n",
    "    else:\n",
    "        rob_str = \"None (DM_p & PT_p ≥ 0.10)\"\n",
    "\n",
    "    print(f\"\\n{panel_name} panel key specs:\")\n",
    "    print(f\"  • Lowest RMSE    : {low['spec_id']} (w={int(low['window'])}, η={low['eta']:.3f})\")\n",
    "    print(f\"  • Highest HitRate: {high['spec_id']} (w={int(high['window'])}, η={high['eta']:.3f})\")\n",
    "    print(f\"  • Robust Winner  : {rob_str}\")\n",
    "\n",
    "# back‑test tables + key specs\n",
    "print(\"\\n=== Back‑test summary (COVID panel) ===\")\n",
    "print(eval_tables[\"mwu\"][\"COVID\"].to_string(index=False))\n",
    "print_key_specs_mwu(eval_tables[\"mwu\"][\"COVID\"], \"COVID\")\n",
    "\n",
    "print(\"\\n=== Back‑test summary (Full panel) ===\")\n",
    "print(eval_tables[\"mwu\"][\"Full\"].to_string(index=False))\n",
    "print_key_specs_mwu(eval_tables[\"mwu\"][\"Full\"], \"Full\")\n",
    "\n",
    "# stratified diagnostics on best‑RMSE spec (Full)\n",
    "best_spec = eval_tables[\"mwu\"][\"Full\"].loc[\n",
    "    eval_tables[\"mwu\"][\"Full\"][\"HitRate\"].idxmax(), \"spec_id\"\n",
    "]\n",
    "print(f\"\\n=== Stratified diagnostics (FULL • best spec {best_spec}) ===\")\n",
    "st_tbl = stratified_mwu(oos_maps[\"mwu\"][\"Full\"][best_spec])\n",
    "print(\"No realised data.\" if st_tbl.empty else st_tbl.to_string(index=False))\n",
    "\n",
    "# consolidated live forecasts\n",
    "print(\"\\n================ CONSOLIDATED LIVE FORECASTS ================\\n\")\n",
    "for panel in [\"COVID\", \"Full\"]:\n",
    "    lv = live_tables[\"mwu\"][panel]\n",
    "    if lv.empty:\n",
    "        continue\n",
    "    ev = eval_tables[\"mwu\"][panel]\n",
    "\n",
    "    selections = {\n",
    "        \"Lowest RMSE\"     : ev.loc[ev[\"RMSE_smart\"].idxmin()],\n",
    "        \"Highest HitRate\" : ev.loc[ev[\"HitRate\"].idxmax()]\n",
    "    }\n",
    "    rob = ev[(ev[\"DM_p\"] < .10) & (ev[\"PT_p\"] < .10)]\n",
    "    if not rob.empty:\n",
    "        selections[\"Robust Winner\"] = rob.loc[rob[\"RMSE_smart\"].idxmin()]\n",
    "\n",
    "    from collections import defaultdict\n",
    "    label_map, spec_info = defaultdict(set), {}\n",
    "    for lbl, row in selections.items():\n",
    "        label_map[row[\"spec_id\"]].add(lbl)\n",
    "        spec_info[row[\"spec_id\"]] = row\n",
    "\n",
    "    for sid, labels in label_map.items():\n",
    "        row = lv[lv[\"spec_id\"] == sid].iloc[-1]\n",
    "        txt = \" & \".join(sorted(labels))\n",
    "        sig = \"Beat\" if row[\"pred_dir\"] else \"Miss\"\n",
    "        print(f\"--- {panel} • {txt} ---\")\n",
    "        print(f\"Date   : {row['date'].date()}\")\n",
    "        print(f\"Smart  : {row['smart']:.1f} k\")\n",
    "        print(f\"Median : {row['median']:.1f} k\")\n",
    "        print(f\"Signal : {sig}  ({sid})\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2278d00e",
   "metadata": {},
   "source": [
    "**Old MWU prototyping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "#  MWU-AddExp · ECONOMIST level\n",
    "#    • 12-month probation with *dynamic* contiguity test\n",
    "#    • back-test starts 2010-01-01\n",
    "#    • first forecast only if ≥5 probated economists\n",
    "#    • per-economist weight-cap = 50 %\n",
    "#    • prints: COVID → Full → stratified (Full) → consolidated live\n",
    "# =============================================================\n",
    "import pandas as pd, numpy as np, itertools, math, scipy.stats as st\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------------- HYPER-PARAMETERS ---------------------------\n",
    "PROBATION_M   = 12\n",
    "INITIAL_T0    = pd.Timestamp(\"2010-01-01\")\n",
    "ALPHA_GRID    = [0.10, 0.20]\n",
    "ETA_GRID      = np.arange(0.001, 0.011, 0.001)\n",
    "CAP           = .50\n",
    "MIN_EXPERTS   = 5\n",
    "EPS_FLOOR     = 1e-8\n",
    "RIDGE         = 1e-6\n",
    "\n",
    "# ---------------- DYNAMIC REGIMES ---------------------------\n",
    "TODAY             = pd.Timestamp.today().normalize()\n",
    "FIRST_DATE        = pd.to_datetime(df_full[\"release_date\"].min()).normalize()\n",
    "TRAILING_START_12 = TODAY - pd.DateOffset(months=12)\n",
    "TRAILING_START_24 = TODAY - pd.DateOffset(months=24)\n",
    "\n",
    "REGIMES = {\n",
    "    f\"{FIRST_DATE:%Y-%m} to 2007-12 (pre-GFC)\"      : (FIRST_DATE, \"2007-12-31\"),\n",
    "    \"2008-01 to 2009-12 (GFC)\"                      : (\"2008-01-01\", \"2009-12-31\"),\n",
    "    \"2010-01-2014-12 (early-expansion, post GFC)\"   : (\"2010-01-01\", \"2014-12-31\"),\n",
    "    \"2015-01-2019-12 (late-expansion, post GFC)\"    : (\"2015-01-01\", \"2019-12-31\"),\n",
    "    \"2020-01 to 2022-12 (COVID)\"                    : (\"2020-01-01\", \"2022-12-31\"),\n",
    "    f\"2023-01 to {TODAY.date()} (post-COVID)\"       : (\"2023-01-01\", TODAY),\n",
    "    \"Trailing 24-months\"                            : (TRAILING_START_24, TODAY),\n",
    "    \"Trailing 12-months\"                            : (TRAILING_START_12, TODAY),\n",
    "}\n",
    "\n",
    "# ---------------- COVERAGE MATRICES --------------------------\n",
    "df_full = df_full.copy()\n",
    "df_full[\"release_date\"] = pd.to_datetime(df_full[\"release_date\"])\n",
    "\n",
    "coverage = (df_full.assign(flag=1)\n",
    "                     .pivot_table(index=\"economist\",\n",
    "                                  columns=\"release_date\",\n",
    "                                  values=\"flag\",\n",
    "                                  aggfunc=\"size\")\n",
    "                     .notna()\n",
    "                     .sort_index(axis=1))\n",
    "\n",
    "first_forecast = df_full.groupby(\"economist\")[\"release_date\"].min()\n",
    "probation_date = first_forecast + pd.DateOffset(months=PROBATION_M)\n",
    "\n",
    "# ---------------- CORE BACK-TESTER ---------------------------\n",
    "def mwu_addexp_panel(panel: pd.DataFrame, alpha: float, eta: float):\n",
    "    pname   = getattr(panel, \"name\", \"panel\")\n",
    "    dates   = np.sort(panel.loc[panel[\"release_date\"] >= INITIAL_T0,\n",
    "                                \"release_date\"].unique())\n",
    "\n",
    "    # initial pool (passed probation *and* contiguous up to INITIAL_T0)\n",
    "    init_exp = [e for e in coverage.index\n",
    "                if (probation_date[e] < INITIAL_T0)\n",
    "                and coverage.loc[e, probation_date[e]:INITIAL_T0].all()]\n",
    "\n",
    "    w = pd.Series(1/len(init_exp), index=init_exp, dtype=float) if init_exp else pd.Series(dtype=float)\n",
    "\n",
    "    spec_id = f\"mwu_eta{eta:.3f}_alpha{alpha:.2f}\"\n",
    "    recs, live_rows, oos_map = [], [], {}\n",
    "\n",
    "    joined = set(init_exp)\n",
    "\n",
    "    for d in dates:\n",
    "\n",
    "        # ------ dynamic newcomer test ----------------------------------\n",
    "        pot = [e for e in coverage.index if e not in joined and d >= probation_date[e]]\n",
    "        newcomers = [e for e in pot if coverage.loc[e, probation_date[e]:d].all()]\n",
    "        if newcomers:\n",
    "            joined.update(newcomers)\n",
    "            w *= (1 - alpha)\n",
    "            w.update(pd.Series(alpha/len(newcomers), index=newcomers))\n",
    "            w.clip(lower=EPS_FLOOR, inplace=True)\n",
    "            w /= w.sum()\n",
    "\n",
    "        # enforce cap\n",
    "        if not w.empty:\n",
    "            w = w.clip(upper=CAP)\n",
    "            w /= w.sum()\n",
    "\n",
    "        # ------ current forecasts -------------------------------------\n",
    "        cur_month = panel.loc[panel[\"release_date\"] == d]\n",
    "        cur_last  = (cur_month[cur_month[\"economist\"].isin(w.index)]\n",
    "                     .sort_values(\"asof\")\n",
    "                     .groupby(\"economist\", as_index=False).last())\n",
    "\n",
    "        f_t   = cur_last.set_index(\"economist\")[\"forecast\"]\n",
    "        avail = f_t.notna(); n_avail = avail.sum()\n",
    "\n",
    "        if n_avail >= MIN_EXPERTS:\n",
    "            w_av  = w.reindex(f_t.index).fillna(0.0) * avail\n",
    "            w_av /= w_av.sum()\n",
    "            smart   = float(np.dot(w_av, f_t.fillna(0.0)))\n",
    "            median  = float(cur_month[\"median_forecast\"].iloc[0])\n",
    "            actual  = float(cur_month[\"actual\"].iloc[0])\n",
    "            recs.append((d, smart, median, actual, int(smart > median)))\n",
    "\n",
    "        # ------ MWU weight update -------------------------------------\n",
    "        if pd.notna(cur_month[\"actual\"].iloc[0]) and n_avail:\n",
    "            y    = cur_month[\"actual\"].iloc[0]\n",
    "            loss = (f_t.fillna(0.0) - y).pow(2) + RIDGE\n",
    "            w *= np.exp(-eta * loss.reindex(w.index).fillna(0.0))\n",
    "            w.clip(lower=EPS_FLOOR, inplace=True)\n",
    "            w = w.clip(upper=CAP)\n",
    "            w /= w.sum()\n",
    "\n",
    "    # ---------- assemble outputs -------------------------------------\n",
    "    if not recs:\n",
    "        return pd.DataFrame(), pd.DataFrame(), {}\n",
    "\n",
    "    oos = pd.DataFrame(recs, columns=[\"date\",\"smart\",\"median\",\"actual\",\"pred_dir\"])\n",
    "    oos_map[spec_id] = oos\n",
    "\n",
    "    if pd.isna(oos.iloc[-1, 3]):   # live row\n",
    "        last = oos.iloc[-1]\n",
    "        live_rows.append({\"spec_id\":spec_id,\"panel\":pname,\n",
    "                          \"date\":last[\"date\"],\"smart\":last[\"smart\"],\n",
    "                          \"median\":last[\"median\"],\"pred_dir\":last[\"pred_dir\"]})\n",
    "\n",
    "    realised = oos.dropna(subset=[\"actual\"]).copy()\n",
    "    realised[\"smart_err\"]  = realised[\"smart\"]  - realised[\"actual\"]\n",
    "    realised[\"median_err\"] = realised[\"median\"] - realised[\"actual\"]\n",
    "    realised[\"actual_dir\"] = (realised[\"actual\"] > realised[\"median\"]).astype(int)\n",
    "\n",
    "    diff = realised[\"smart_err\"]**2 - realised[\"median_err\"]**2\n",
    "    dm_p = (2*(1-st.norm.cdf(abs(diff.mean()/diff.std(ddof=1)\n",
    "                       * math.sqrt(len(realised)))))) \\\n",
    "           if diff.std(ddof=1) else 1.0\n",
    "\n",
    "    eval_row = {\n",
    "        \"spec_id\"    : spec_id,\n",
    "        \"panel\"      : pname,\n",
    "        \"alpha\"      : alpha,\n",
    "        \"eta\"        : eta,\n",
    "        \"obs\"        : len(realised),\n",
    "        \"RMSE_smart\" : math.sqrt((realised[\"smart_err\"]**2).mean()),\n",
    "        \"RMSE_median\": math.sqrt((realised[\"median_err\"]**2).mean()),\n",
    "        \"SmartBetter\": int(((realised[\"smart_err\"]**2).mean()\n",
    "                            < (realised[\"median_err\"]**2).mean())),\n",
    "        \"HitRate\"    : (realised[\"pred_dir\"] == realised[\"actual_dir\"]).mean(),\n",
    "        \"Binom_p\"    : st.binomtest(\n",
    "                           (realised[\"pred_dir\"] == realised[\"actual_dir\"]).sum(),\n",
    "                           len(realised), .5).pvalue,\n",
    "        \"PT_p\"       : st.binomtest(\n",
    "                           (realised[\"pred_dir\"] & realised[\"actual_dir\"]).sum(),\n",
    "                           len(realised), .25).pvalue,\n",
    "        \"DM_p\"       : dm_p\n",
    "    }\n",
    "    return pd.DataFrame([eval_row]), pd.DataFrame(live_rows), oos_map\n",
    "\n",
    "# ---------------- stratified, printing helpers --------------- (unchanged)\n",
    "def stratified_mwu(oos: pd.DataFrame) -> pd.DataFrame:\n",
    "    # ... (same as previous message, keep unchanged)\n",
    "    df = oos.dropna(subset=[\"actual\"]).copy()\n",
    "    if df.empty: return pd.DataFrame()\n",
    "    df[\"smart_err\"]  = df[\"smart\"]  - df[\"actual\"]\n",
    "    df[\"median_err\"] = df[\"median\"] - df[\"actual\"]\n",
    "    df[\"pred_dir\"]   = (df[\"smart\"] > df[\"median\"]).astype(int)\n",
    "    df[\"actual_dir\"] = (df[\"actual\"] > df[\"median\"]).astype(int)\n",
    "    rows=[]\n",
    "    for lbl,(s,e) in REGIMES.items():\n",
    "        sub=df[(df[\"date\"]>=s)&(df[\"date\"]<=e)]\n",
    "        if sub.empty: continue\n",
    "        rows.append({\n",
    "            \"Regime\":lbl,\"Obs\":len(sub),\n",
    "            \"RMSE_smart\":math.sqrt((sub[\"smart_err\"]**2).mean()),\n",
    "            \"RMSE_median\":math.sqrt((sub[\"median_err\"]**2).mean()),\n",
    "            \"SmartBetter\":int(((sub[\"smart_err\"]**2).mean()\n",
    "                                < (sub[\"median_err\"]**2).mean())),\n",
    "            \"HitRate\":(sub[\"pred_dir\"]==sub[\"actual_dir\"]).mean(),\n",
    "            \"Binom_p\":st.binomtest((sub[\"pred_dir\"]==sub[\"actual_dir\"]).sum(),\n",
    "                                   len(sub),.5).pvalue,\n",
    "            \"PT_p\":st.binomtest((sub[\"pred_dir\"]&sub[\"actual_dir\"]).sum(),\n",
    "                                len(sub),.25).pvalue,\n",
    "            \"DM_p\":st.ttest_rel(sub[\"smart_err\"]**2,\n",
    "                                sub[\"median_err\"]**2).pvalue})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ---------------- GRID RUN -----------------------------------\n",
    "PANELS = {\"COVID\": df.copy(), \"Full\": df_full.copy()}\n",
    "eval_tbls, live_tbls, oos_maps = {}, {}, {}\n",
    "\n",
    "for pname, pnl in PANELS.items():\n",
    "    pnl.name = pname\n",
    "    ev_list, lv_list, omap = [], [], {}\n",
    "    for alpha, eta in tqdm(itertools.product(ALPHA_GRID, ETA_GRID),\n",
    "                           total=len(ALPHA_GRID)*len(ETA_GRID),\n",
    "                           desc=f\"{pname} grid\"):\n",
    "        ev, lv, om = mwu_addexp_panel(pnl, alpha, eta)\n",
    "        ev_list.append(ev); lv_list.append(lv); omap.update(om)\n",
    "    eval_tbls[pname] = pd.concat(ev_list, ignore_index=True)\\\n",
    "                         .sort_values([\"RMSE_smart\",\"eta\"]) if ev_list else pd.DataFrame()\n",
    "    live_tbls[pname] = pd.concat(lv_list, ignore_index=True)\n",
    "    oos_maps[pname]  = omap\n",
    "\n",
    "pd.set_option(\"display.float_format\",\"{:.3f}\".format)\n",
    "\n",
    "# ---------------- NICE PRINTING ------------------------------\n",
    "def label_dict(table):\n",
    "    if table.empty: return {}\n",
    "    out={}\n",
    "    out.setdefault(table.loc[table[\"RMSE_smart\"].idxmin(),\"spec_id\"], {\"Lowest RMSE\"})\n",
    "    out.setdefault(table.loc[table[\"HitRate\"].idxmax(),\"spec_id\"], {\"Highest HitRate\"})\n",
    "    robust = table[(table[\"SmartBetter\"]==1)&(table[\"DM_p\"]<.10)&(table[\"PT_p\"]<.10)]\n",
    "    if not robust.empty:\n",
    "        out.setdefault(robust.loc[robust[\"RMSE_smart\"].idxmin(),\"spec_id\"], {\"Robust Winner\"})\n",
    "    return out\n",
    "\n",
    "def print_backtests():\n",
    "    for panel in [\"COVID\",\"Full\"]:\n",
    "        tbl = eval_tbls[panel]\n",
    "        print(f\"\\n=== Back-test summary ({panel} panel) ===\")\n",
    "        if tbl.empty: print(\"No realised observations.\"); continue\n",
    "        cols = [\"spec_id\",\"panel\",\"alpha\",\"eta\",\"obs\",\"RMSE_smart\",\"RMSE_median\",\n",
    "                \"SmartBetter\",\"HitRate\",\"Binom_p\",\"PT_p\",\"DM_p\"]\n",
    "        print(tbl[cols].to_string(index=False))\n",
    "        keys = label_dict(tbl)\n",
    "        if keys:\n",
    "            print(f\"\\n{panel} panel key specs:\")\n",
    "            for sp,labs in keys.items():\n",
    "                print(f\"  • {' & '.join(sorted(labs))}: {sp}\")\n",
    "\n",
    "def print_stratified():\n",
    "    full_tbl = eval_tbls[\"Full\"]\n",
    "    if full_tbl.empty: return\n",
    "    best_spec = full_tbl.loc[full_tbl[\"HitRate\"].idxmax(),\"spec_id\"]\n",
    "    print(f\"\\n=== Stratified diagnostics (FULL • best spec {best_spec}) ===\")\n",
    "    print(stratified_mwu(oos_maps[\"Full\"][best_spec]).to_string(index=False))\n",
    "\n",
    "def print_live():\n",
    "    combined={}\n",
    "    for panel,tbl in eval_tbls.items():\n",
    "        for sp,labs in label_dict(tbl).items():\n",
    "            combined.setdefault((panel,sp),set()).update(labs)\n",
    "    if not combined: return\n",
    "    print(\"\\n================ CONSOLIDATED LIVE FORECASTS ================\\n\")\n",
    "    for (panel,sp),labs in combined.items():\n",
    "        live = live_tbls[panel]\n",
    "        if sp not in live[\"spec_id\"].values: continue\n",
    "        row = live[live[\"spec_id\"]==sp].iloc[-1]\n",
    "        verdict = \"Beat\" if row[\"pred_dir\"] else \"Miss\"\n",
    "        print(f\"--- {panel} • {' & '.join(sorted(labs))} ---\")\n",
    "        print(f\"Date   : {row['date'].date()}\")\n",
    "        print(f\"Smart  : {row['smart']:.1f} k\")\n",
    "        print(f\"Median : {row['median']:.1f} k\")\n",
    "        print(f\"Signal : {verdict}  ({sp})\\n\")\n",
    "\n",
    "print_backtests()\n",
    "print_stratified()\n",
    "print_live()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e20f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "#  MWU-AddExp  ·  ECONOMIST level  ·  regime-frozen expert pools\n",
    "#    • 12-month contiguity filter at regime start\n",
    "#    • experts may “sleep” ≤ MAX_SLEEP consecutive releases\n",
    "#    • back-test runs separately over the fixed structural regimes\n",
    "#    • optional per-economist weight-cap (set WEIGHT_CAP = 0 for “no cap”)\n",
    "# =============================================================\n",
    "import pandas as pd, numpy as np, itertools, math, scipy.stats as st\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ─────────── USER-TUNABLE KNOBS ───────────────────────────────\n",
    "ETA_GRID     = np.arange(0.001, 0.011, .001)   # MWU learning-rates\n",
    "WEIGHT_CAP   = 0                             # 0.0 → no cap\n",
    "MIN_EXPERTS  = 5                               # smart forecast printed only if ≥ MIN_EXPERTS active\n",
    "PROBATION_M  = 12                              # contiguity window at regime start\n",
    "MAX_SLEEP    = 2                               # ≥ MAX_SLEEP + 1 misses ⇒ expert dropped\n",
    "EPS_FLOOR    = 1e-8\n",
    "RIDGE        = 1e-6\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "# ---------- regime anchors -------------------------------------------------\n",
    "TODAY      = pd.Timestamp.today().normalize()\n",
    "FIRST_DATE = pd.to_datetime(df_full[\"release_date\"].min()).normalize()\n",
    "\n",
    "REGIMES = {\n",
    "    f\"{FIRST_DATE:%Y-%m} to 2007-12 (pre-GFC)\"     : (\"2003-06-01\", \"2007-12-31\"),\n",
    "    \"2008-01 to 2009-12 (GFC)\"                     : (\"2008-01-01\", \"2009-12-31\"),\n",
    "    \"2010-01-2014-12 (early-expansion post-GFC)\"   : (\"2010-01-01\", \"2014-12-31\"),\n",
    "    \"2015-01-2019-12 (late-expansion post-GFC)\"    : (\"2015-01-01\", \"2019-12-31\"),\n",
    "    \"2020-01 to 2022-12 (COVID)\"                   : (\"2020-01-01\", \"2022-12-31\"),\n",
    "    f\"2023-01 to {TODAY.date()} (post-COVID)\"      : (\"2023-01-01\", TODAY),\n",
    "}\n",
    "\n",
    "# ---------- coverage matrices ---------------------------------------------\n",
    "df_full = df_full.copy()\n",
    "df_full[\"release_date\"] = pd.to_datetime(df_full[\"release_date\"])\n",
    "\n",
    "coverage = (df_full.assign(flag=1)\n",
    "                     .pivot_table(index=\"economist\",\n",
    "                                  columns=\"release_date\",\n",
    "                                  values=\"flag\",\n",
    "                                  aggfunc=\"size\")\n",
    "                     .notna()\n",
    "                     .sort_index(axis=1))\n",
    "\n",
    "first_forecast = df_full.groupby(\"economist\")[\"release_date\"].min()\n",
    "prob_date      = first_forecast + pd.DateOffset(months=PROBATION_M)\n",
    "\n",
    "# ---------- helpers --------------------------------------------------------\n",
    "def contiguous_pool(start):\n",
    "    \"\"\"\n",
    "    Pool of economists that (i) satisfied probation by `start`\n",
    "    and (ii) have no missing forecasts in the 12-month window\n",
    "    [start-12M … start-1d].\n",
    "    \"\"\"\n",
    "    lbeg = start - pd.DateOffset(months=PROBATION_M)\n",
    "    lend = start - pd.DateOffset(days=1)\n",
    "    return [e for e in coverage.index\n",
    "            if prob_date[e] <= start\n",
    "            and coverage.loc[e, lbeg:lend].all()]\n",
    "\n",
    "def run_regime(panel, pool, eta):\n",
    "    \"\"\"MWU-AddExp within one regime for a *fixed* expert pool.\"\"\"\n",
    "    if not pool:\n",
    "        return [], []\n",
    "\n",
    "    w      = pd.Series(1/len(pool), index=pool, dtype=float)          # equal start\n",
    "    sleep  = pd.Series(0, index=pool, dtype=int)                      # consecutive-miss counter\n",
    "    rows   = []                                                       # OOS performance rows\n",
    "    w_hist = []                                                       # (date, weight vector) snapshots\n",
    "\n",
    "    for d, grp in panel.groupby(\"release_date\", sort=True):\n",
    "        # latest forecasts from active experts\n",
    "        cur = (grp[grp[\"economist\"].isin(w.index)]\n",
    "               .sort_values(\"asof\")\n",
    "               .groupby(\"economist\", as_index=False)\n",
    "               .last())\n",
    "        f_t     = cur.set_index(\"economist\")[\"forecast\"]\n",
    "        avail   = f_t.notna()\n",
    "        n_avail = avail.sum()\n",
    "\n",
    "        if n_avail >= MIN_EXPERTS:  # produce smart forecast\n",
    "            w_av  = w.reindex(f_t.index).fillna(0.0) * avail\n",
    "            w_av /= w_av.sum()\n",
    "            smart   = float(np.dot(w_av, f_t.fillna(0.0)))\n",
    "            median  = float(grp[\"median_forecast\"].iloc[0])\n",
    "            actual  = float(grp[\"actual\"].iloc[0])\n",
    "            rows.append((d, smart, median, actual, int(smart > median)))\n",
    "            w_hist.append((d, w.copy()))\n",
    "\n",
    "        # MWU weight update after realisation\n",
    "        if pd.notna(grp[\"actual\"].iloc[0]) and n_avail:\n",
    "            y    = grp[\"actual\"].iloc[0]\n",
    "            loss = (f_t.fillna(0.0) - y).pow(2) + RIDGE\n",
    "            w *= np.exp(-eta * loss.reindex(w.index).fillna(0.0))\n",
    "\n",
    "        # sleep bookkeeping\n",
    "        sleepers = sleep.index.difference(cur[\"economist\"])\n",
    "        sleep.loc[sleepers] += 1\n",
    "        sleep.loc[cur[\"economist\"]] = 0\n",
    "        to_drop = sleep[sleep > MAX_SLEEP].index\n",
    "        if len(to_drop):\n",
    "            w.drop(to_drop, inplace=True)\n",
    "            sleep.drop(to_drop, inplace=True)\n",
    "\n",
    "        # cap + renormalise\n",
    "        if WEIGHT_CAP > 0:\n",
    "            w.clip(upper=WEIGHT_CAP, inplace=True)\n",
    "        w.clip(lower=EPS_FLOOR, inplace=True)\n",
    "        w /= w.sum()\n",
    "\n",
    "    return rows, w_hist\n",
    "\n",
    "# ---------- grid runner ----------------------------------------------------\n",
    "def backtest(panel_name, df_panel):\n",
    "    eval_rows, live_rows, oos_map = [], [], {}\n",
    "    for eta in tqdm(ETA_GRID, desc=f\"{panel_name} grid\"):\n",
    "        all_oos = []\n",
    "        for label, (start, end) in REGIMES.items():\n",
    "            start_ts = pd.Timestamp(start); end_ts = pd.Timestamp(end)\n",
    "            mask = (df_panel[\"release_date\"] >= start_ts) & (df_panel[\"release_date\"] <= end_ts)\n",
    "            if not mask.any(): continue\n",
    "            pool = contiguous_pool(start_ts)\n",
    "            oos, _ = run_regime(df_panel.loc[mask], pool, eta)\n",
    "            all_oos.extend(oos)\n",
    "\n",
    "        if not all_oos:\n",
    "            continue\n",
    "\n",
    "        spec_id = f\"mwu_eta{eta:.3f}\"\n",
    "        oos_df  = pd.DataFrame(all_oos, columns=[\"date\",\"smart\",\"median\",\"actual\",\"pred_dir\"])\n",
    "        oos_map[spec_id] = oos_df\n",
    "\n",
    "        # live row (if last actual still NA)\n",
    "        if oos_df[\"actual\"].isna().iloc[-1]:\n",
    "            last = oos_df.iloc[-1]\n",
    "            live_rows.append({\"spec_id\":spec_id,\"panel\":panel_name,\n",
    "                              \"date\":last[\"date\"],\"smart\":last[\"smart\"],\n",
    "                              \"median\":last[\"median\"],\"pred_dir\":last[\"pred_dir\"]})\n",
    "\n",
    "        # evaluation\n",
    "        realised = oos_df.dropna(subset=[\"actual\"])\n",
    "        if realised.empty: continue\n",
    "        realised[\"smart_err\"]  = realised[\"smart\"]  - realised[\"actual\"]\n",
    "        realised[\"median_err\"] = realised[\"median\"] - realised[\"actual\"]\n",
    "        realised[\"actual_dir\"] = (realised[\"actual\"] > realised[\"median\"]).astype(int)\n",
    "        diff = realised[\"smart_err\"]**2 - realised[\"median_err\"]**2\n",
    "        dm_p = (2*(1-st.norm.cdf(abs(diff.mean()/diff.std(ddof=1)\n",
    "                           * math.sqrt(len(realised)))))) if diff.std(ddof=1) else 1.0\n",
    "        eval_rows.append({\n",
    "            \"spec_id\":spec_id,\"panel\":panel_name,\"eta\":eta,\n",
    "            \"obs\":len(realised),\n",
    "            \"RMSE_smart\":math.sqrt((realised[\"smart_err\"]**2).mean()),\n",
    "            \"RMSE_median\":math.sqrt((realised[\"median_err\"]**2).mean()),\n",
    "            \"SmartBetter\":int(((realised[\"smart_err\"]**2).mean()\n",
    "                               < (realised[\"median_err\"]**2).mean())),\n",
    "            \"HitRate\":(realised[\"pred_dir\"]==realised[\"actual_dir\"]).mean(),\n",
    "            \"Binom_p\":st.binomtest((realised[\"pred_dir\"]==realised[\"actual_dir\"]).sum(),\n",
    "                                   len(realised),.5).pvalue,\n",
    "            \"PT_p\":st.binomtest((realised[\"pred_dir\"]&realised[\"actual_dir\"]).sum(),\n",
    "                                len(realised),.25).pvalue,\n",
    "            \"DM_p\":dm_p\n",
    "        })\n",
    "    return pd.DataFrame(eval_rows), pd.DataFrame(live_rows), oos_map\n",
    "\n",
    "# ---------- run COVID & FULL panels ---------------------------------------\n",
    "PANELS = {\"COVID\": df.copy(),          # df = COVID subset already in memory\n",
    "          \"Full\" : df_full.copy()}\n",
    "\n",
    "eval_tbls, live_tbls, oos_maps = {}, {}, {}\n",
    "for name, pnl in PANELS.items():\n",
    "    pnl.name = name\n",
    "    eval_tbls[name], live_tbls[name], oos_maps[name] = backtest(name, pnl)\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "# ---------- reporting helpers ---------------------------------------------\n",
    "def label_specs(tbl):\n",
    "    if tbl.empty: return {}\n",
    "    out={}\n",
    "    out.setdefault(tbl.loc[tbl[\"RMSE_smart\"].idxmin(),\"spec_id\"], {\"Lowest RMSE\"})\n",
    "    out.setdefault(tbl.loc[tbl[\"HitRate\"].idxmax(),\"spec_id\"], {\"Highest HitRate\"})\n",
    "    robust = tbl[(tbl[\"SmartBetter\"]==1)&(tbl[\"DM_p\"]<.10)&(tbl[\"PT_p\"]<.10)]\n",
    "    if not robust.empty:\n",
    "        out.setdefault(robust.loc[robust[\"RMSE_smart\"].idxmin(),\"spec_id\"], {\"Robust Winner\"})\n",
    "    return out\n",
    "\n",
    "def print_backtests():\n",
    "    for name in [\"COVID\",\"Full\"]:\n",
    "        tbl = eval_tbls[name]\n",
    "        print(f\"\\n=== Back-test summary ({name} panel) ===\")\n",
    "        if tbl.empty: print(\"No realised observations.\"); continue\n",
    "        cols = [\"spec_id\",\"eta\",\"obs\",\"RMSE_smart\",\"RMSE_median\",\n",
    "                \"SmartBetter\",\"HitRate\",\"Binom_p\",\"PT_p\",\"DM_p\"]\n",
    "        print(tbl[cols].to_string(index=False))\n",
    "        for sp,lbs in label_specs(tbl).items():\n",
    "            print(f\"  • {' & '.join(sorted(lbs))}: {sp}\")\n",
    "\n",
    "def print_stratified():\n",
    "    full = eval_tbls[\"Full\"]\n",
    "    if full.empty: return\n",
    "    best = full.loc[full[\"HitRate\"].idxmax(),\"spec_id\"]\n",
    "    print(f\"\\n=== Stratified diagnostics (FULL • best spec {best}) ===\")\n",
    "    print(stratified_mwu(oos_maps[\"Full\"][best]).to_string(index=False))\n",
    "\n",
    "def print_live():\n",
    "    combined={}\n",
    "    for p,t in eval_tbls.items():\n",
    "        for sp,lbs in label_specs(t).items():\n",
    "            combined.setdefault((p,sp),set()).update(lbs)\n",
    "    if not combined: return\n",
    "    print(\"\\n================ CONSOLIDATED LIVE FORECASTS ================\\n\")\n",
    "    for (p,sp),lbs in combined.items():\n",
    "        live = live_tbls[p]\n",
    "        if sp not in live[\"spec_id\"].values: continue\n",
    "        r = live[live[\"spec_id\"]==sp].iloc[-1]\n",
    "        verdict = \"Beat\" if r[\"pred_dir\"] else \"Miss\"\n",
    "        print(f\"--- {p} • {' & '.join(sorted(lbs))} ---\")\n",
    "        print(f\"Date   : {r['date'].date()}\")\n",
    "        print(f\"Smart  : {r['smart']:.1f} k\")\n",
    "        print(f\"Median : {r['median']:.1f} k\")\n",
    "        print(f\"Signal : {verdict}  ({sp})\\n\")\n",
    "\n",
    "print_backtests()\n",
    "print_stratified()\n",
    "print_live()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a843e3",
   "metadata": {},
   "source": [
    "Legacy MWU implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5321fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "#  Multiplicative Weights Update\n",
    "# =============================================================\n",
    "ETA_GRID     = np.arange(0.001, 0.011, .001)   # MWU learning-rates\n",
    "WEIGHT_CAP   = 0.50                            # highest weight we're willing to weigh a single forecaster; 0 = no cap\n",
    "MIN_EXPERTS  = 5\n",
    "PROBATION_M  = 12                              # contiguity window\n",
    "MAX_SLEEP    = 3                               # drop after 4 misses\n",
    "EPS_FLOOR    = 1e-8\n",
    "RIDGE        = 1e-6                            # tiny ridge for stability\n",
    "\n",
    "# define coverage matrixs\n",
    "df_full = df_full.copy()\n",
    "df_full[\"release_date\"] = pd.to_datetime(df_full[\"release_date\"])\n",
    "\n",
    "coverage = (df_full.assign(flag=1)\n",
    "                     .pivot_table(index=\"economist\",\n",
    "                                  columns=\"release_date\",\n",
    "                                  values=\"flag\",\n",
    "                                  aggfunc=\"size\")\n",
    "                     .notna()\n",
    "                     .sort_index(axis=1))\n",
    "\n",
    "first_forecast = df_full.groupby(\"economist\")[\"release_date\"].min()\n",
    "prob_date      = first_forecast + pd.DateOffset(months=PROBATION_M)\n",
    "\n",
    "def contiguous_pool(start: pd.Timestamp) -> list[str]:\n",
    "    \"\"\"Experts with a clean 12-month window (passing 12-release probation) ending just before `start`.\"\"\"\n",
    "    lbeg = start - pd.DateOffset(months=PROBATION_M)\n",
    "    lend = start - pd.DateOffset(days=1)\n",
    "    return [e for e in coverage.index\n",
    "            if prob_date[e] <= start and coverage.loc[e, lbeg:lend].all()]\n",
    "\n",
    "def run_regime(panel: pd.DataFrame, pool: list[str], eta: float):\n",
    "    \"\"\"\n",
    "    Performs MWU for a single regime. \n",
    "    \"\"\"\n",
    "    if not pool:\n",
    "        return [], []                                   # no experts\n",
    "\n",
    "    w      = pd.Series(1/len(pool), index=pool, dtype=float)\n",
    "    sleep  = pd.Series(0, index=pool, dtype=int)\n",
    "    rows, hist = [], []                                # OOS rows, weight history\n",
    "\n",
    "    for d, grp in panel.groupby(\"release_date\", sort=True):\n",
    "        cur = (grp[grp[\"economist\"].isin(w.index)]\n",
    "               .sort_values(\"asof\")\n",
    "               .groupby(\"economist\", as_index=False)\n",
    "               .last())\n",
    "        f_t   = cur.set_index(\"economist\")[\"forecast\"]\n",
    "        avail = f_t.notna()\n",
    "\n",
    "        # record smart forecast\n",
    "        if avail.sum() >= MIN_EXPERTS:\n",
    "            w_av = w.reindex(f_t.index).fillna(0.0) * avail\n",
    "            w_av /= w_av.sum()\n",
    "            smart  = float(np.dot(w_av, f_t.fillna(0.0)))\n",
    "            median = float(grp[\"median_forecast\"].iloc[0])\n",
    "            actual = float(grp[\"actual\"].iloc[0])\n",
    "            rows.append((d, smart, median, actual, int(smart > median)))\n",
    "            hist.append((d, w.copy()))\n",
    "\n",
    "        # MWU weight update\n",
    "        if pd.notna(grp[\"actual\"].iloc[0]) and avail.any():\n",
    "            loss = (f_t.fillna(0.0) - grp[\"actual\"].iloc[0]).pow(2) + RIDGE\n",
    "            w *= np.exp(-eta * loss.reindex(w.index).fillna(0.0))\n",
    "\n",
    "        # \"sleep\" bookkeeping \n",
    "        sleepers = sleep.index.difference(cur[\"economist\"])\n",
    "        sleep.loc[sleepers] += 1\n",
    "        sleep.loc[cur[\"economist\"]] = 0\n",
    "        to_drop = sleep[sleep > MAX_SLEEP].index\n",
    "        if len(to_drop):\n",
    "            w.drop(to_drop, inplace=True)\n",
    "            sleep.drop(to_drop, inplace=True)\n",
    "\n",
    "        # cap and renormalize if any single forecaster exceeds cap\n",
    "        if WEIGHT_CAP > 0:\n",
    "            w.clip(upper=WEIGHT_CAP, inplace=True)\n",
    "        w.clip(lower=EPS_FLOOR, inplace=True)\n",
    "        w /= w.sum()\n",
    "\n",
    "    return rows, hist                                    # list, list[(date,w)]\n",
    "\n",
    "\n",
    "def backtest_mwu(panel_name: str, df_panel: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Runs the MWU backtesting grid.\n",
    "    \"\"\"\n",
    "    eval_rows, live_rows, oos_map = [], [], {}\n",
    "\n",
    "    for eta in tqdm(ETA_GRID, desc=f\"{panel_name} grid\"):\n",
    "        all_oos, all_hist = [], []\n",
    "        for start, end in REGIMES.values():\n",
    "            mask = (df_panel[\"release_date\"] >= start) & (df_panel[\"release_date\"] <= end)\n",
    "            if not mask.any():\n",
    "                continue\n",
    "            pool = contiguous_pool(pd.Timestamp(start))\n",
    "            oos, hist = run_regime(df_panel.loc[mask], pool, eta)\n",
    "            all_oos.extend(oos)\n",
    "            all_hist.extend(hist)\n",
    "\n",
    "        if not all_oos:\n",
    "            continue\n",
    "\n",
    "        spec_id = f\"mwu_eta{eta:.3f}\"\n",
    "        oos_df  = pd.DataFrame(all_oos,\n",
    "                               columns=[\"date\",\"smart\",\"median\",\"actual\",\"pred_dir\"])\n",
    "        oos_map[spec_id] = oos_df\n",
    "\n",
    "        # live row + weight snapshot\n",
    "        if oos_df[\"actual\"].isna().iloc[-1]:\n",
    "            last = oos_df.iloc[-1]\n",
    "            live_rows.append({\n",
    "                \"spec_id\": spec_id, \"panel\": panel_name,\n",
    "                \"date\":    last[\"date\"], \"smart\":  last[\"smart\"],\n",
    "                \"median\":  last[\"median\"], \"pred_dir\": last[\"pred_dir\"]\n",
    "            })\n",
    "            live_dt = last[\"date\"]\n",
    "            w_last  = next((w for d, w in reversed(all_hist) if d == live_dt), None)\n",
    "            if w_last is not None:\n",
    "                meta = {\"date\": live_dt, \"panel\": panel_name,\n",
    "                        \"model\": \"mwu\", \"spec\": spec_id}\n",
    "                for econ, wt in w_last.items():\n",
    "                    LIVE_WEIGHT_SNAPSHOTS.append(\n",
    "                        {**meta, \"economist\": econ, \"weight\": float(wt)}\n",
    "                    )\n",
    "\n",
    "        # realized evaluation\n",
    "        realised = oos_df.dropna(subset=[\"actual\"])\n",
    "        if realised.empty:\n",
    "            continue\n",
    "        realised[\"smart_err\"]  = realised[\"smart\"]  - realised[\"actual\"]\n",
    "        realised[\"median_err\"] = realised[\"median\"] - realised[\"actual\"]\n",
    "        realised[\"actual_dir\"] = (realised[\"actual\"] > realised[\"median\"]).astype(int)\n",
    "        diff = realised[\"smart_err\"]**2 - realised[\"median_err\"]**2\n",
    "        dm_p = (1.0 if diff.std(ddof=1)==0 else\n",
    "                2*(1 - st.norm.cdf(abs(diff.mean()/diff.std(ddof=1)\n",
    "                                        * math.sqrt(len(realised))))))\n",
    "        eval_rows.append({\n",
    "            \"spec_id\":     spec_id,\n",
    "            \"panel\":       panel_name,\n",
    "            \"eta\":         eta,\n",
    "            \"obs\":         len(realised),\n",
    "            \"RMSE_smart\":  math.sqrt((realised[\"smart_err\"]**2).mean()),\n",
    "            \"RMSE_median\": math.sqrt((realised[\"median_err\"]**2).mean()),\n",
    "            \"SmartBetter\": int(((realised[\"smart_err\"]**2).mean()\n",
    "                                < (realised[\"median_err\"]**2).mean())),\n",
    "            \"HitRate\":     (realised[\"pred_dir\"] == realised[\"actual_dir\"]).mean(),\n",
    "            \"Binom_p\":     st.binomtest(\n",
    "                               (realised[\"pred_dir\"] == realised[\"actual_dir\"]).sum(),\n",
    "                               len(realised), .5).pvalue,\n",
    "            \"PT_p\":        st.binomtest(\n",
    "                               (realised[\"pred_dir\"] & realised[\"actual_dir\"]).sum(),\n",
    "                               len(realised), .25).pvalue,\n",
    "            \"DM_p\":        dm_p\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(eval_rows), pd.DataFrame(live_rows), oos_map\n",
    "\n",
    "# ---------- run for both panels ------------------------------\n",
    "PANELS = {\"COVID\": df.copy(), \"Full\": df_full.copy()}\n",
    "\n",
    "# scratch dicts used only by the legacy print helpers\n",
    "mwu_eval_tbls = {}\n",
    "mwu_live_tbls = {}\n",
    "mwu_oos_tbls  = {}\n",
    "\n",
    "for pname, pnl in PANELS.items():\n",
    "    pnl.name = pname               # nice for tqdm\n",
    "\n",
    "    ev, lv, om = backtest_mwu(pname, pnl)\n",
    "\n",
    "    mwu_eval_tbls[pname] = ev\n",
    "    mwu_live_tbls[pname] = lv\n",
    "    mwu_oos_tbls [pname] = om\n",
    "\n",
    "    # push into the global, 3-level container\n",
    "    #    (model  ➜  panel  ➜  spec_id  ➜  DataFrame)\n",
    "    eval_tables.setdefault(\"mwu\", {})[pname] = ev\n",
    "    live_tables.setdefault(\"mwu\", {})[pname] = lv\n",
    "    oos_maps   .setdefault(\"mwu\", {})[pname] = om\n",
    "\n",
    "    # actual directions cache (for later diagnostics)\n",
    "    actual_dir.setdefault(\"mwu\", {})[pname] = (\n",
    "        np.array([], dtype=int) if ev.empty else\n",
    "        (next(iter(om.values()))\n",
    "            .dropna(subset=[\"actual\"])\n",
    "            .assign(flag=lambda d: (d[\"actual\"] > d[\"median\"]).astype(int))[\"flag\"]\n",
    "            .values)\n",
    "    )\n",
    "\n",
    "    _all_eval.append(ev)\n",
    "    _all_live.append(lv)\n",
    "\n",
    "def label_specs(tbl):\n",
    "    \"\"\"Return {spec_id → set(labels)} accumulating multiple titles.\"\"\"\n",
    "    if tbl.empty:\n",
    "        return {}\n",
    "    out = defaultdict(set)\n",
    "    out[tbl.loc[tbl[\"RMSE_smart\"].idxmin(), \"spec_id\"]].add(\"Lowest RMSE\")\n",
    "    out[tbl.loc[tbl[\"HitRate\"].idxmax(),   \"spec_id\"]].add(\"Highest HitRate\")\n",
    "    rob = tbl[(tbl[\"SmartBetter\"]==1) & (tbl[\"DM_p\"]<.10) & (tbl[\"PT_p\"]<.10)]\n",
    "    if not rob.empty:\n",
    "        out[rob.loc[rob[\"RMSE_smart\"].idxmin(), \"spec_id\"]].add(\"Robust Winner\")\n",
    "    return out\n",
    "\n",
    "# ---------- printing and stratified helpers ------------------------------\n",
    "def print_backtests():\n",
    "    for name in [\"COVID\", \"Full\"]:\n",
    "        tbl = mwu_eval_tbls[name]                  \n",
    "        print(f\"\\n=== Back-test summary ({name} panel) ===\")\n",
    "        if tbl.empty:\n",
    "            print(\"No realised observations.\"); continue\n",
    "        cols = [\"spec_id\",\"eta\",\"obs\",\"RMSE_smart\",\"RMSE_median\",\n",
    "                \"SmartBetter\",\"HitRate\",\"Binom_p\",\"PT_p\",\"DM_p\"]\n",
    "        print(tbl[cols].to_string(index=False))\n",
    "        for sp, lbs in label_specs(tbl).items():\n",
    "            print(f\"  • {' & '.join(sorted(lbs))}: {sp}\")\n",
    "\n",
    "def stratified_mwu(oos_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = oos_df.dropna(subset=[\"actual\"]).copy()\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "    df[\"smart_err\"]  = df[\"smart\"]  - df[\"actual\"]\n",
    "    df[\"median_err\"] = df[\"median\"] - df[\"actual\"]\n",
    "    df[\"pred_dir\"]   = (df[\"smart\"] > df[\"median\"]).astype(int)\n",
    "    df[\"actual_dir\"] = (df[\"actual\"] > df[\"median\"]).astype(int)\n",
    "\n",
    "    rows = []\n",
    "    for lbl, (s, e) in REGIMES.items():\n",
    "        sub = df[(df[\"date\"] >= s) & (df[\"date\"] <= e)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        rows.append({\n",
    "            \"Regime\"      : lbl,\n",
    "            \"Obs\"         : len(sub),\n",
    "            \"RMSE_smart\"  : math.sqrt((sub[\"smart_err\"]**2).mean()),\n",
    "            \"RMSE_median\" : math.sqrt((sub[\"median_err\"]**2).mean()),\n",
    "            \"SmartBetter\" : int(((sub[\"smart_err\"]**2).mean()\n",
    "                                  < (sub[\"median_err\"]**2).mean())),\n",
    "            \"HitRate\"     : (sub[\"pred_dir\"] == sub[\"actual_dir\"]).mean(),\n",
    "            \"Binom_p\"     : st.binomtest(\n",
    "                               (sub[\"pred_dir\"] == sub[\"actual_dir\"]).sum(),\n",
    "                               len(sub), .5).pvalue,\n",
    "            \"PT_p\"        : st.binomtest(\n",
    "                               (sub[\"pred_dir\"] & sub[\"actual_dir\"]).sum(),\n",
    "                               len(sub), .25).pvalue,\n",
    "            \"DM_p\"        : st.ttest_rel(sub[\"smart_err\"]**2,\n",
    "                                         sub[\"median_err\"]**2).pvalue\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def print_stratified():\n",
    "    full = mwu_eval_tbls[\"Full\"]                    \n",
    "    if full.empty:\n",
    "        return\n",
    "    best = full.loc[full[\"HitRate\"].idxmax(), \"spec_id\"]\n",
    "    print(f\"\\n=== Stratified diagnostics (FULL • best spec {best}) ===\")\n",
    "    print(stratified_mwu(mwu_oos_tbls[\"Full\"][best]).to_string(index=False))  \n",
    "\n",
    "def print_live():\n",
    "    combined = {}\n",
    "    for p, tbl in mwu_eval_tbls.items():            \n",
    "        for sp, lbs in label_specs(tbl).items():\n",
    "            combined.setdefault((p, sp), set()).update(lbs)\n",
    "    if not combined:\n",
    "        return\n",
    "    print(\"\\n================ CONSOLIDATED LIVE FORECASTS ================\\n\")\n",
    "    for (p, sp), lbs in combined.items():\n",
    "        lv = mwu_live_tbls[p]                       \n",
    "        if sp not in lv[\"spec_id\"].values:\n",
    "            continue\n",
    "        r = lv[lv[\"spec_id\"] == sp].iloc[-1]\n",
    "        verdict = \"Beat\" if r[\"pred_dir\"] else \"Miss\"\n",
    "        print(f\"--- {p} • {' & '.join(sorted(lbs))} ---\")\n",
    "        print(f\"Date   : {r['date'].date()}\")\n",
    "        print(f\"Smart  : {r['smart']:.1f} k\")\n",
    "        print(f\"Median : {r['median']:.1f} k\")\n",
    "        print(f\"Signal : {verdict}  ({sp})\\n\")\n",
    "\n",
    "# console output\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "print_backtests()\n",
    "print_stratified()\n",
    "print_live()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
