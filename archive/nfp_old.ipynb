{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb13ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Beta version: Let's listen to only the most accurate forecasters\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Top-N forecaster ensemble â€¢ mean vs inverse-MSE weighting\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import norm, binomtest\n",
    "\n",
    "# ðŸ”‡â€ƒsuppress every warning category\n",
    "warnings.filterwarnings(\"ignore\")          # â† one line does it all\n",
    "np.seterr(all=\"ignore\")                    # silence NumPy runtime warnings\n",
    "\n",
    "WINDOWS = [3, 6, 12]\n",
    "TOP_NS  = [5, 10, 15, 20, 25]\n",
    "RIDGE   = 1e-6\n",
    "\n",
    "PANELS = {\"Full panel\": df_full, \"COVID-filtered panel\": df}\n",
    "\n",
    "def evaluate_panel(panel: pd.DataFrame, label: str) -> pd.DataFrame:\n",
    "    dates = np.sort(panel[\"release_date\"].unique())\n",
    "    metrics = []\n",
    "\n",
    "    for W in tqdm(WINDOWS, desc=f\"{label}: windows\"):\n",
    "        for N in TOP_NS:\n",
    "            rows = []\n",
    "\n",
    "            for idx in range(W, len(dates)):\n",
    "                t = dates[idx]\n",
    "                hist = panel[panel[\"release_date\"]\n",
    "                             .between(dates[idx - W], dates[idx - 1])]\n",
    "\n",
    "                elig = hist.groupby(\"economist\")[\"forecast\"].apply(lambda s: s.notna().all())\n",
    "                econs = elig[elig].index\n",
    "                if econs.empty:\n",
    "                    continue\n",
    "\n",
    "                mse = (hist[hist[\"economist\"].isin(econs)]\n",
    "                       .groupby(\"economist\")[\"error\"]\n",
    "                       .apply(lambda s: np.mean(s**2)))\n",
    "                top = mse.nsmallest(N).index          # up to N forecasters\n",
    "\n",
    "                cur = panel[(panel[\"release_date\"] == t) &\n",
    "                            (panel[\"economist\"].isin(top))]\n",
    "                f_t = cur.set_index(\"economist\")[\"forecast\"].dropna()\n",
    "                if f_t.empty:\n",
    "                    continue\n",
    "\n",
    "                weights = {\n",
    "                    \"mean\": pd.Series(1 / len(f_t), index=f_t.index),\n",
    "                    \"inv_mse\": 1 / (mse.loc[f_t.index] + RIDGE)\n",
    "                }\n",
    "                weights[\"inv_mse\"] /= weights[\"inv_mse\"].sum()\n",
    "\n",
    "                median_all = panel.loc[panel[\"release_date\"] == t,\n",
    "                                       \"forecast\"].dropna().median()\n",
    "                actual = panel.loc[panel[\"release_date\"] == t,\n",
    "                                   \"actual\"].iloc[0]\n",
    "\n",
    "                for method, w in weights.items():\n",
    "                    smart = np.dot(w, f_t)\n",
    "                    pred_dir = int(smart > median_all)\n",
    "                    actual_dir = int(actual > median_all) if pd.notna(actual) else np.nan\n",
    "                    rows.append((W, len(f_t), method, t,\n",
    "                                 smart, median_all, actual,\n",
    "                                 pred_dir, actual_dir))\n",
    "\n",
    "            if not rows:\n",
    "                continue\n",
    "\n",
    "            df_all = pd.DataFrame(rows, columns=[\n",
    "                \"window\", \"top_N\", \"method\", \"date\",\n",
    "                \"smart\", \"median\", \"actual\", \"pred_dir\", \"actual_dir\"\n",
    "            ])\n",
    "            eval_df = df_all.dropna(subset=[\"actual\"])\n",
    "            if eval_df.empty:\n",
    "                continue\n",
    "\n",
    "            eval_df[\"smart_err\"]  = eval_df[\"smart\"]  - eval_df[\"actual\"]\n",
    "            eval_df[\"median_err\"] = eval_df[\"median\"] - eval_df[\"actual\"]\n",
    "\n",
    "            obs     = len(eval_df)\n",
    "            rmse_s  = np.sqrt((eval_df[\"smart_err\"]**2).mean())\n",
    "            rmse_m  = np.sqrt((eval_df[\"median_err\"]**2).mean())\n",
    "\n",
    "            diff = eval_df[\"smart_err\"]**2 - eval_df[\"median_err\"]**2\n",
    "            dm_p = 2 * (1 - norm.cdf(abs(diff.mean() / diff.std(ddof=1) *\n",
    "                                         np.sqrt(obs))))\n",
    "\n",
    "            # directional metrics\n",
    "            hits     = (eval_df[\"pred_dir\"] == eval_df[\"actual_dir\"]).sum()\n",
    "            hit_rate = hits / obs\n",
    "            binom_p  = binomtest(hits, obs, 0.5).pvalue\n",
    "\n",
    "            p1, p2 = eval_df[\"pred_dir\"].mean(), eval_df[\"actual_dir\"].mean()\n",
    "            joint  = ((eval_df[\"pred_dir\"].astype(int) &\n",
    "                       eval_df[\"actual_dir\"].astype(int))).mean()\n",
    "            pt_stat = (joint - p1 * p2) / np.sqrt(p1 * p2 * (1 - p1) * (1 - p2) / obs)\n",
    "            pt_p    = 2 * (1 - norm.cdf(abs(pt_stat)))\n",
    "\n",
    "            metrics.append({\n",
    "                \"window\": W, \"top_N\": N, \"method\": method, \"obs\": obs,\n",
    "                \"RMSE_smart\": rmse_s, \"RMSE_median\": rmse_m,\n",
    "                \"HitRate\": hit_rate, \"Binom_p\": binom_p,\n",
    "                \"PT_stat\": pt_stat, \"PT_p\": pt_p, \"DM_p\": dm_p\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "for name, pdf in PANELS.items():\n",
    "    tbl = (evaluate_panel(pdf, name)\n",
    "           .sort_values([\"window\", \"top_N\", \"method\"])\n",
    "           .reset_index(drop=True))\n",
    "    print(f\"\\n--- {name} : Top-N ensemble (mean vs inv_mse) ---\")\n",
    "    print(tbl.to_string(index=False))\n",
    "\n",
    "### Beta version: Let's listen only to forecasters that reacted to the ADP print\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# â€œFresh-updateâ€ ensemble:\n",
    "# â€¢ keep only forecasts with |asof âˆ’ release_date| â‰¤ 3 days\n",
    "# â€¢ smart forecasts:   mean  &  median   of those â€œfreshâ€ forecasts\n",
    "# â€¢ three directional signals:\n",
    "#       pred_dir_mean   (mean > crowd median)\n",
    "#       pred_dir_med    (median > crowd median)\n",
    "#       pred_dir_vote   (majority of fresh forecasters above crowd median)\n",
    "# â€¢ evaluation on realised months\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np, pandas as pd, warnings\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import norm, binomtest\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "PANELS = {\n",
    "    \"Full panel\"          : df_full,   # assume in memory\n",
    "    \"COVID-filtered panel\": df\n",
    "}\n",
    "\n",
    "def evaluate_fresh(panel: pd.DataFrame, label: str) -> pd.DataFrame:\n",
    "    # Â±3-day mask (absolute difference â‰¤ 3 days)\n",
    "    panel = panel.copy()\n",
    "    panel[\"asof_delta\"] = (panel[\"release_date\"] - panel[\"asof\"]).abs().dt.days\n",
    "    panel[\"is_fresh\"]   = panel[\"asof_delta\"] <= 3\n",
    "\n",
    "    dates   = np.sort(panel[\"release_date\"].unique())\n",
    "    rows    = []\n",
    "\n",
    "    for t in tqdm(dates, desc=label):\n",
    "        month_all   = panel[panel[\"release_date\"] == t]\n",
    "        month_fresh = month_all[month_all[\"is_fresh\"]]\n",
    "\n",
    "        if month_fresh.empty:        # no qualifying forecasts\n",
    "            continue\n",
    "\n",
    "        crowd_med = month_all[\"forecast\"].dropna().median()\n",
    "        smart_mean = month_fresh[\"forecast\"].mean()\n",
    "        smart_med  = month_fresh[\"forecast\"].median()\n",
    "\n",
    "        # individual vote: 1 if their forecast > crowd median\n",
    "        voter_flags = (month_fresh[\"forecast\"] > crowd_med).astype(int)\n",
    "        pred_dir_vote = int(voter_flags.mean() > 0.5)   # strict majority\n",
    "\n",
    "        # level-based directions\n",
    "        pred_dir_mean = int(smart_mean > crowd_med)\n",
    "        pred_dir_med  = int(smart_med  > crowd_med)\n",
    "\n",
    "        actual = month_all[\"actual\"].iloc[0]\n",
    "\n",
    "        rows.append((t, smart_mean, smart_med, crowd_med, actual,\n",
    "                     pred_dir_mean, pred_dir_med, pred_dir_vote))\n",
    "\n",
    "    cols = [\"date\",\"smart_mean\",\"smart_med\",\"crowd_median\",\"actual\",\n",
    "            \"dir_mean\",\"dir_med\",\"dir_vote\"]\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "    eval_df = df.dropna(subset=[\"actual\"])\n",
    "    if eval_df.empty:\n",
    "        return pd.DataFrame()       # nothing to score\n",
    "\n",
    "    # errors versus actual\n",
    "    eval_df[\"err_mean\"] = eval_df[\"smart_mean\"] - eval_df[\"actual\"]\n",
    "    eval_df[\"err_med\"]  = eval_df[\"smart_med\"]  - eval_df[\"actual\"]\n",
    "    eval_df[\"err_crowd\"]= eval_df[\"crowd_median\"] - eval_df[\"actual\"]\n",
    "\n",
    "    # helper for directional metrics\n",
    "    def dir_metrics(flag_col):\n",
    "        hits = (eval_df[flag_col] == (eval_df[\"actual\"] > eval_df[\"crowd_median\"]).astype(int)).sum()\n",
    "        hit_rate = hits / len(eval_df)\n",
    "        binom_p  = binomtest(hits, len(eval_df), 0.5).pvalue\n",
    "        p1, p2 = eval_df[flag_col].mean(), (eval_df[\"actual\"] > eval_df[\"crowd_median\"]).mean()\n",
    "        joint  = (eval_df[flag_col].astype(int) &\n",
    "                  (eval_df[\"actual\"] > eval_df[\"crowd_median\"]).astype(int)).mean()\n",
    "        pt_stat = (joint - p1*p2) / np.sqrt(p1*p2*(1-p1)*(1-p2)/len(eval_df))\n",
    "        pt_p    = 2*(1 - norm.cdf(abs(pt_stat)))\n",
    "        return hit_rate, binom_p, pt_stat, pt_p\n",
    "\n",
    "    rmse_mean = np.sqrt((eval_df[\"err_mean\"]**2).mean())\n",
    "    rmse_med  = np.sqrt((eval_df[\"err_med\"]**2 ).mean())\n",
    "    rmse_crowd= np.sqrt((eval_df[\"err_crowd\"]**2).mean())\n",
    "\n",
    "    # Diebold-Mariano (smart_mean vs crowd median)\n",
    "    diff_mean = eval_df[\"err_mean\"]**2 - eval_df[\"err_crowd\"]**2\n",
    "    dm_p_mean = 2*(1 - norm.cdf(abs(diff_mean.mean()/diff_mean.std(ddof=1) *\n",
    "                                     np.sqrt(len(eval_df)))))\n",
    "\n",
    "    # Diebold-Mariano (smart_med vs crowd median)\n",
    "    diff_med  = eval_df[\"err_med\"]**2 - eval_df[\"err_crowd\"]**2\n",
    "    dm_p_med  = 2*(1 - norm.cdf(abs(diff_med.mean()/diff_med.std(ddof=1) *\n",
    "                                     np.sqrt(len(eval_df)))))\n",
    "\n",
    "    # directional stats\n",
    "    hit_mn, bin_mn, pt_mn, ptp_mn = dir_metrics(\"dir_mean\")\n",
    "    hit_md, bin_md, pt_md, ptp_md = dir_metrics(\"dir_med\")\n",
    "    hit_vt, bin_vt, pt_vt, ptp_vt = dir_metrics(\"dir_vote\")\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        \"obs\": len(eval_df),\n",
    "        \"RMSE_mean\":   rmse_mean,\n",
    "        \"RMSE_medianSmart\": rmse_med,\n",
    "        \"RMSE_crowdMedian\": rmse_crowd,\n",
    "        \"DM_p_mean\":   dm_p_mean,\n",
    "        \"DM_p_medianSmart\": dm_p_med,\n",
    "        # directional metrics\n",
    "        \"HitRate_mean\": hit_mn,   \"Binom_p_mean\": bin_mn, \"PT_p_mean\": ptp_mn,\n",
    "        \"HitRate_med\":  hit_md,   \"Binom_p_med\":  bin_md, \"PT_p_med\":  ptp_md,\n",
    "        \"HitRate_vote\": hit_vt,   \"Binom_p_vote\": bin_vt, \"PT_p_vote\": ptp_vt\n",
    "    }])\n",
    "\n",
    "# ---------- run & display ----------\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "for name, pdf in PANELS.items():\n",
    "    tbl = evaluate_fresh(pdf, name)\n",
    "    print(f\"\\n--- {name} : 3-day fresh-update ensemble ---\")\n",
    "    if tbl.empty:\n",
    "        print(\"No months qualified (no fresh forecasts found).\")\n",
    "    else:\n",
    "        print(tbl.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389a2c6",
   "metadata": {},
   "source": [
    "## 0: Baseline static forecast on full sample\n",
    "\n",
    "Rolling 6-month fixed window. For every valid economist (for a prediction at time t, has a contiguous 6-month forecast history for previous 6 releases), weight prediction by inverse MSE. \n",
    "\n",
    "\n",
    "This implements an out-of-sample error estimate with a rolling 6-month estimation window. Weights don't use information from the target month and actual value at month *t* is unseen. In other words, all errors are \"live\" errors that could have been observed in real time.\n",
    "\n",
    "Briefly, the procedure: \n",
    "1. Starts at 7th release (for 6 month release prior)\n",
    "2. From estimation window, keep economists that supplied a forecast for all six months (per contiguity rule)\n",
    "3. Compute MSE for each economist using errors against already known actuals (no lookahead)\n",
    "4. Generate forecast for release t \n",
    "5. Store OOS evaluation error\n",
    "6. Roll window forward a month and repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f680372",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
